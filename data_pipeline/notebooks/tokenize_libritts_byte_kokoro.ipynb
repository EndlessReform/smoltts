{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize LibriTTS-R Mimi for target LM\n",
    "\n",
    "For our dataset, we currently simply use the Fish Speech TTS format:\n",
    "- Text-only data formatted using [ChatML](https://gist.github.com/edwardzjl/8df07c1f7140c9a3e2f48d33a8032090) as a separate sequence \"above\" the audio code stream\n",
    "- During sections where audio is being modeled, text stream 0 predicts the first semantic token index $n$ of the 8 Mimi residual codes as special token `<|semantic:n|>`\n",
    "- For audio, \"semantic\" (neural, there's not a strong distinction between) codes (from Mimi) padded with 0s during text sections\n",
    "\n",
    "It's possible this tokenization strategy can be improved, e.g. in [Defossez et al. 2024](https://arxiv.org/html/2410.00037v2#S3.SS4.SSS4) with the base transformer predicting the Whisper-timestamped word timings as an \"inner monologue\" and a delay between codebook timesteps. lol i'll do it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 576820/576820 [00:01<00:00, 302411.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset, DatasetDict, concatenate_datasets, load_from_disk\n",
    "from data_pipeline.utils.prompt import PromptEncoder, TokenizationConfig\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "# If creating the libritts dataset for the first time\n",
    "# dataset = load_from_disk(\"../../Kokoro-82M/libritts_r_mimi_kokoro\")\n",
    "dataset = load_dataset(\"jkeisling/project-gutenberg-kokoro-2K\", token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "# full_train = concatenate_datasets([dataset[\"train.clean.100\"], dataset[\"train.clean.360\"]])\n",
    "\n",
    "# dataset = DatasetDict({\n",
    "#     \"train\": full_train,\n",
    "#     \"val\": dataset[\"dev.clean\"],\n",
    "#     \"test\": dataset[\"test.clean\"]\n",
    "# })\n",
    "# dataset = DatasetDict({\"full\": dataset})\n",
    "dataset = dataset.with_format(\"torch\")\n",
    "# dataset = dataset.remove_columns([\"chapter_id\", \"text_original\"])\n",
    "# dataset = dataset.rename_column(original_column_name=\"text_normalized\", new_column_name=\"normalized_text\")\n",
    "dataset = dataset.rename_column(original_column_name=\"sentences\", new_column_name=\"text_normalized\")\n",
    "\n",
    "config = TokenizationConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=12): 100%|██████████| 576820/576820 [00:02<00:00, 248711.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "FRAMERATE = 12.5\n",
    "# NOTE: DELETE THIS, HARD-CODED ASSUMPTION\n",
    "dataset = dataset.filter(lambda row: row[\"codes\"].size(-1) <= 15 * FRAMERATE, num_proc=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE! This is PATH DEPENDENT on ADDING THE SEMANTIC TOKENS TO THE TOKENIZER EARLIER using `create_bytelevel_init.ipynb`. DO NOT SKIP THIS STEP OR THE MODEL WILL BE IRRETRIEVABLY BROKEN! YOU HAVE BEEN WARNED.**\n",
    "\n",
    "==**THIS IS BYTE LEVEL!**=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../../inits/smoltts_byte_kokoro\")\n",
    "tokenizer.use_default_system_prompt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this carefully: for byte level, it should be 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2368, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer), tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please manually verify the text is done correctly. However, DECODE will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: tensor([[269, 256,  10, 260, 261, 270]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n<|american|><|male|><|im_end|>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tokenizer by encoding and decoding some example text\n",
    "example_text = \"<|im_start|>system\\n<|american|><|male|><|im_end|>\"\n",
    "encoded = tokenizer(example_text, return_tensors=\"pt\")\n",
    "print(f\"Encoded: {encoded['input_ids']}\")\n",
    "decoded = tokenizer.decode(encoded['input_ids'][0])\n",
    "\n",
    "# Print the results\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[269, 257,  10, 104, 101, 108, 112,  32, 109, 101,  32, 105,  32,  97,\n",
       "         109,  32, 116, 114,  97, 112, 112, 101, 100,  32, 105, 110,  32, 116,\n",
       "         104, 105, 115,  32,  99, 111, 109, 112, 117, 116, 101, 114, 270,  10,\n",
       "         269, 258,  10]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": \"help me i am trapped in this computer\"}], add_generation_prompt=True,  return_tensors=\"pt\")\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n<|speaker:40|><|im_end|>\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "prompt_encoder = PromptEncoder(tokenizer, config)\n",
    "tts_sysprompt = prompt_encoder.encode_text_turn(role=\"system\", content=\"<|speaker:40|>\", add_generation_prompt=False)\n",
    "tokenizer.decode(tts_sysprompt[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this assumes you're using ChatML. if you're NOT, then there's quite a bit more to fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|semantic:1049|><|semantic:127|><|semantic:1880|><|semantic:1031|><|semantic:1031|><|semantic:1031|><|semantic:1492|><|semantic:1492|><|semantic:1926|><|semantic:1926|><|semantic:1826|><|semantic:1268|><|semantic:1001|><|semantic:382|><|semantic:587|><|semantic:178|><|semantic:1380|><|semantic:1380|><|semantic:1790|><|semantic:117|><|semantic:130|><|semantic:531|><|semantic:2036|><|semantic:722|><|semantic:1470|><|semantic:1725|><|semantic:371|><|semantic:728|><|semantic:774|><|semantic:1677|><|semantic:518|><|semantic:769|><|semantic:666|><|semantic:84|><|semantic:84|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:1926|><|semantic:1926|><|semantic:1926|><|semantic:1926|><|im_end|>\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = prompt_encoder.encode_vq(dataset[\"full\"][0][\"codes\"])\n",
    "tokenizer.decode(out[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|semantic:1049|><|semantic:127|><|semantic:1880|><|semantic:1031|><|semantic:1031|><|semantic:1031|><|semantic:1492|><|semantic:1492|><|semantic:1926|><|semantic:1926|><|semantic:1826|><|semantic:1268|><|semantic:1001|><|semantic:382|><|semantic:587|><|semantic:178|><|semantic:1380|><|semantic:1380|><|semantic:1790|><|semantic:117|><|semantic:130|><|semantic:531|><|semantic:2036|><|semantic:722|><|semantic:1470|><|semantic:1725|><|semantic:371|><|semantic:728|><|semantic:774|><|semantic:1677|><|semantic:518|><|semantic:769|><|semantic:666|><|semantic:84|><|semantic:84|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:1926|><|semantic:1926|><|semantic:1926|><|semantic:1926|><|im_end|>\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_corrupt = prompt_encoder.encode_vq_corrupt(dataset[\"full\"][0][\"codes\"])\n",
    "tokenizer.decode(out_corrupt[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_names = [\"default\", \"sarah\", \"sky\", \"adam\", \"emma\", \"isabella\", \"george\", \"lewis\"]\n",
    "speaker_ids = {value: index for index, value in enumerate(speaker_names)}\n",
    "speaker_ids[\"adam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n<|speaker:1|><|im_end|>\\n<|im_start|>assistant\\n<|im_start|>user\\nUncle Roland was gone.<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:127|><|semantic:1880|><|semantic:1031|><|semantic:1031|><|semantic:1031|><|semantic:1492|><|semantic:1492|><|semantic:1926|><|semantic:1926|><|semantic:1826|><|semantic:824|><|semantic:1754|><|semantic:1177|><|semantic:1823|><|semantic:526|><|semantic:1260|><|semantic:1998|><|semantic:95|><|semantic:622|><|semantic:382|><|semantic:1238|><|semantic:160|><|semantic:1597|><|semantic:1663|><|semantic:1528|><|semantic:1987|><|semantic:666|><|semantic:716|><|semantic:84|><|semantic:84|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:1926|><|semantic:1926|><|semantic:1926|><|semantic:1926|><|im_end|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "# import random\n",
    "\n",
    "# TODO: Not doing ASR for now\n",
    "def tts_tokenize_row(row: Dict):\n",
    "    \"\"\"\n",
    "    NOTE: Deliberately ignores sysprompt line for now, can be done in packing\n",
    "    \"\"\"\n",
    "    # TODO: Fix this upstream in the data gen!\n",
    "    # gender = \"<|male|>\" if row[\"speaker_id\"] in [\"george\", \"lewis\", \"adam\", \"michael\"] else \"<|female|>\"\n",
    "    # accent = f\"<|{row['accent']}|>\"\n",
    "    # speaker = f\"<|speaker:{speaker_ids[row['speaker_id']]}|>\" if random.random() < 0.7 else \"\"\n",
    "    speaker = f\"<|speaker:{speaker_ids[row['speaker_id']]}|>\"\n",
    "\n",
    "    # Just keep it all for now, will test generalization later\n",
    "    system_line = prompt_encoder.encode_text_turn(role=\"system\", content=\"\".join([speaker]))\n",
    "    user_line = prompt_encoder.encode_text_turn(\n",
    "        role=\"user\", \n",
    "        content=row[\"text_normalized\"].encode(\"utf-8\").decode(\"latin-1\"), \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    assistant_line = prompt_encoder.encode_vq(row[\"codes\"])\n",
    "    ground_truth = torch.cat([system_line, user_line, assistant_line], dim=1)\n",
    "    # ground_truth = torch.cat([user_line, assistant_line], dim=1)\n",
    "    # Causal shift\n",
    "    tokens = ground_truth[:,:-1].clone()\n",
    "    labels = ground_truth[:,1:].clone()\n",
    "\n",
    "    # Assuming user line took care of assistant prefix \n",
    "    # Offsetting by 1 since labels were shifted\n",
    "    text_only_length = system_line.size(1) + user_line.size(1) - 1\n",
    "    labels[1:, :text_only_length] = -100\n",
    "    # Mask out im_end and newline\n",
    "    labels[1:, -2:] = -100\n",
    "\n",
    "    return({\n",
    "        \"tokens\": tokens,\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    \n",
    "\n",
    "\n",
    "example_row = tts_tokenize_row(dataset[\"full\"][10])\n",
    "tokenizer.decode(example_row[\"tokens\"][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n<|speaker:1|><|im_end|>\\n<|im_start|>assistant\\n<|im_start|>user\\nUncle Roland was gone.<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:127|><|semantic:1880|><|semantic:1031|><|semantic:1031|><|semantic:1031|><|semantic:1492|><|semantic:1492|><|semantic:1926|><|semantic:1926|><|semantic:1826|><|semantic:824|><|semantic:1754|><|semantic:1177|><|semantic:1823|><|semantic:526|><|semantic:1260|><|semantic:1998|><|semantic:95|><|semantic:622|><|semantic:382|><|semantic:1238|><|semantic:160|><|semantic:1597|><|semantic:1663|><|semantic:1528|><|semantic:1987|><|semantic:666|><|semantic:716|><|semantic:84|><|semantic:84|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:752|><|semantic:1926|><|semantic:1926|><|semantic:1926|><|semantic:1926|><|im_end|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from typing import Dict\n",
    "# import random\n",
    "\n",
    "# TODO: Not doing ASR for now\n",
    "def tts_tokenize_row_dropout(row: Dict):\n",
    "    \"\"\"\n",
    "    NOTE: Deliberately ignores sysprompt line for now, can be done in packing\n",
    "    \"\"\"\n",
    "    # TODO: Fix this upstream in the data gen!\n",
    "    # gender = \"<|male|>\" if row[\"speaker_id\"] in [\"george\", \"lewis\", \"adam\", \"michael\"] else \"<|female|>\"\n",
    "    # accent = f\"<|{row['accent']}|>\"\n",
    "    # speaker = f\"<|speaker:{speaker_ids[row['speaker_id']]}|>\" if random.random() < 0.7 else \"\"\n",
    "    speaker = f\"<|speaker:{speaker_ids[row['speaker_id']]}|>\"\n",
    "\n",
    "    # Just keep it all for now, will test generalization later\n",
    "    system_line = prompt_encoder.encode_text_turn(role=\"system\", content=\"\".join([speaker]))\n",
    "    user_line = prompt_encoder.encode_text_turn(\n",
    "        role=\"user\", \n",
    "        content=row[\"text_normalized\"].encode(\"utf-8\").decode(\"latin-1\"), \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    assistant_line_true = prompt_encoder.encode_vq(row[\"codes\"])\n",
    "    assistant_line_dropout = prompt_encoder.encode_vq_corrupt(row[\"codes\"], dropout=0.3)\n",
    "    messy_input = torch.cat([system_line, user_line, assistant_line_dropout], dim=1)\n",
    "    ground_truth = torch.cat([system_line, user_line, assistant_line_true], dim=1)\n",
    "    # Causal shift\n",
    "    tokens = messy_input[:,:-1]\n",
    "    labels = ground_truth[:,1:]\n",
    "\n",
    "    # Assuming user line took care of assistant prefix \n",
    "    # Offsetting by 1 since labels were shifted\n",
    "    text_only_length = system_line.size(1) + user_line.size(1) - 1\n",
    "    labels[1:, :text_only_length] = -100\n",
    "    # Mask out im_end and newline\n",
    "    labels[1:, -2:] = -100\n",
    "\n",
    "    return({\n",
    "        \"tokens\": tokens,\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    \n",
    "\n",
    "\n",
    "example_row = tts_tokenize_row_dropout(dataset[\"full\"][10])\n",
    "tokenizer.decode(example_row[\"tokens\"][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 269,  256,   10,  272,  270,   10,  269,  258,   10,  269,  257,   10,\n",
       "           85,  110,   99,  108,  101,   32,   82,  111,  108,   97,  110,  100,\n",
       "           32,  119,   97,  115,   32,  103,  111,  110,  101,   46,  270,   10,\n",
       "          269,  258,   10, 1369,  447, 2200, 1351, 1351, 1351, 1812, 1812, 2246,\n",
       "         2246, 2146, 1144, 2074, 1497, 2143,  846, 1580, 2318,  415,  942,  702,\n",
       "         1558,  480, 1917, 1983, 1848, 2307,  986, 1036,  404,  404, 1072, 1072,\n",
       "         1072, 1072, 2246, 2246, 2246, 2246,  270],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0, 1049,  127, 1880, 1031, 1031, 1031, 1492, 1492, 1926,\n",
       "         1926, 1826,  824, 1754, 1177, 1823,  526, 1260, 1998,   95,  622,  382,\n",
       "         1238,  160, 1597, 1663, 1528, 1987,  666,  716,   84,   84,  752,  752,\n",
       "          752,  752, 1926, 1926, 1926, 1926,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0, 1700,  243,  243, 1899,  243,  243, 1211,  243,  243,\n",
       "         1314, 1768,  988,  365, 1599,  505, 1964, 1792, 1783,  846, 2008, 1340,\n",
       "          438,  159, 1736, 1884,  985, 1515,  243,  243,   27,  410,  243,  243,\n",
       "         1693,  243,  243,  243, 2025, 1650,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,  994,  783, 1178, 1886, 1178, 1178, 1381, 1712, 1559,\n",
       "          339, 1697,  508,  294,  187, 1500, 1013, 1141,  523, 1169, 2003,  782,\n",
       "          651,  776, 1288,  903,  286, 1669,  677, 1559, 1697, 1178, 1559, 1559,\n",
       "         1559,  980, 1559, 1329, 1178, 1238,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,  901,  546,  546,  290,  142,  435,  546,  142,  164,\n",
       "          164,  546, 1207,  929,  529,  303, 1881, 1899,  836, 1829, 1543, 1528,\n",
       "          885,  722, 1254, 1335, 2029,  488,  593,  473,  164,  546,   14,  546,\n",
       "          768,  164,  164, 1224,  809,  546,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,  306, 1193,  481, 1736, 1115,  481, 1015,  481, 1736,\n",
       "         1736, 1335, 1138, 1321,  988,   52,  835, 1424,  691, 2033, 1138, 1207,\n",
       "          582,  113, 1074, 1655,  731,  340, 1736, 1450, 1736, 2019, 1736, 1736,\n",
       "          481,  921, 1107, 1736,  481,  481,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0, 1443,   39, 1430, 1572, 1572, 1572, 1572, 1030, 1030,\n",
       "         1462,  555,  916, 1031, 1118,  853,  463,  546, 1446,   56, 1118,  182,\n",
       "          686, 1629,  541,   28, 1432,  317,  582, 2038, 1030, 1030, 1572, 1030,\n",
       "          600, 1443, 1443, 1030, 1030, 1572,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0, 1871,  457, 1133, 1104, 1978,  825, 1978, 1978,  666,\n",
       "          666, 1109, 1262, 2016,  858, 1449,  809,   16, 1972,  615, 1072, 1644,\n",
       "          518,  639, 1088, 1592,  726, 1785,  666, 1978, 1966, 1099,  651, 1205,\n",
       "          825,  976,  613,  433, 1396,  825,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0, 2008,  318,  534, 2008, 1648, 1648, 1648, 1456, 1744,\n",
       "          290, 1648, 1473,  188,  500, 1926, 1740, 1715,  714, 1815, 1180,  769,\n",
       "          442, 1417,  599,  791, 1538, 1180, 1744, 1744, 1744,  812, 1744, 1744,\n",
       "         1744, 1581, 1744, 1744,  806, 1744,    0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 256,   10,  272,  270,   10,  269,  258,   10,  269,  257,   10,   85,\n",
       "          110,   99,  108,  101,   32,   82,  111,  108,   97,  110,  100,   32,\n",
       "          119,   97,  115,   32,  103,  111,  110,  101,   46,  270,   10,  269,\n",
       "          258,   10, 1369,  447, 2200, 1351, 1351, 1351, 1812, 1812, 2246, 2246,\n",
       "         2146, 1144, 2074, 1497, 2143,  846, 1580, 2318,  415,  942,  702, 1558,\n",
       "          480, 1917, 1983, 1848, 2307,  986, 1036,  404,  404, 1072, 1072, 1072,\n",
       "         1072, 2246, 2246, 2246, 2246,  270,   10],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, 1049,  127, 1880, 1031, 1031, 1031, 1492, 1492, 1926, 1926,\n",
       "         1826,  824, 1754, 1177, 1823,  526, 1260, 1998,   95,  622,  382, 1238,\n",
       "          160, 1597, 1663, 1528, 1987,  666,  716,   84,   84,  752,  752,  752,\n",
       "          752, 1926, 1926, 1926, 1926, -100, -100],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, 1700,  243,  243,  243,  243,  243, 1211,  243,  243,  243,\n",
       "         1050,  988,  305, 1599,  505,  412, 1454, 1401,  846, 2008, 1995,  438,\n",
       "          159, 1736, 1092,  985, 1515,  243,  243,  243,  243,  243,  243,  243,\n",
       "          243,  243,  243,  243,  243, -100, -100],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, 1626,  783, 1178, 1178, 1178, 1178, 1697, 1178, 1559, 1559,\n",
       "         1697,  508,  294,  219,   29, 1013, 1141,  523, 1169, 2003,  782,  651,\n",
       "          776,   77,  903,  286, 1212, 1697, 1559, 1697, 1178, 1559, 1559, 1559,\n",
       "         1559, 1559, 1178, 1178, 1178, -100, -100],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100,  546,  546,  546,  290,  142,  142,  546,  142,  164,  164,\n",
       "          546, 1207,  929,  529,  303, 1881, 1899, 1941, 1829,  397,  200, 1216,\n",
       "          722, 1254, 1335,  231,  488,  164,  546,  164,  546,  546,  546,  546,\n",
       "          164,  164,  290,  546,  546, -100, -100],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100,  306,  481,  481, 1736,  481,  481, 1736,  481, 1736, 1736,\n",
       "         1335, 1138, 1321,  988,   52, 2029, 1424,  691, 2033, 1138, 1207,  582,\n",
       "          113, 1419, 1655,  731,  340, 1736, 1736, 1736,  267, 1736, 1736,  481,\n",
       "          267,  267, 1736,  481,  481, -100, -100],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, 1443,  555, 1030, 1572, 1572, 1572, 1572, 1030, 1030, 1030,\n",
       "          555,  916,   25, 1118,  853,  463,  546, 1446,   56, 1118,  182,  686,\n",
       "         1629,  541,  739,  870,  317, 1030, 1443, 1030, 1030, 1572, 1030, 1030,\n",
       "         1443, 1443, 1030, 1030, 1572, -100, -100],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, 1871,  666,  825,  825, 1978,  825, 1978, 1978,  666,  666,\n",
       "          976, 1262, 2016,  858, 1449,  809,   16, 1972,  695, 1072, 1644, 1835,\n",
       "          639, 1088, 1592,  726,  819,  666, 1978,  666, 1978, 1978, 1978,  825,\n",
       "          976,  976,  666,  666,  825, -100, -100],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, 2008, 1648, 1744, 2008, 1648, 1648, 1648, 1648, 1744, 1744,\n",
       "         1648, 1473, 1818,  500, 1926,  336, 1715,  714, 1567,  623,  769,  442,\n",
       "         1417,  599,  791, 1538, 1180, 1744, 1744, 1744, 1744, 1744, 1744, 1744,\n",
       "         1744, 1744, 1744, 1744, 1744, -100, -100]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=24): 100%|██████████| 539921/539921 [00:46<00:00, 11506.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# DO NOT INCREASE batch size\n",
    "dataset = dataset.map(tts_tokenize_row, remove_columns=\"codes\", num_proc=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (36/36 shards): 100%|██████████| 539921/539921 [01:03<00:00, 8533.77 examples/s] \n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk(\"../../datasets/tokenized_project_gutenberg_bytes_kokoro_tau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens shape: torch.Size([2, 9, 8])\n",
      "\n",
      "First sequence tokens:\n",
      "tensor([[ 21,  17,  10,  78,  48, 999, 999, 999],\n",
      "        [ 58,   6,  85,  54,  88,   0,   0,   0],\n",
      "        [ 97,  89,   7,  37,  36,   0,   0,   0],\n",
      "        [ 91,  37,  32,   9,  76,   0,   0,   0],\n",
      "        [ 73,  23,  67,  80,  82,   0,   0,   0],\n",
      "        [ 91,  63,  17,  87,  50,   0,   0,   0],\n",
      "        [ 28,  65,  62,  31,  80,   0,   0,   0],\n",
      "        [  5,  30,  70,  23,  44,   0,   0,   0],\n",
      "        [ 36,  82,  58,  98,  18,   0,   0,   0]])\n",
      "\n",
      "Second sequence tokens:\n",
      "tensor([[37, 99, 29, 58, 78, 19, 17, 26],\n",
      "        [23, 59,  2, 53, 83, 66,  1, 38],\n",
      "        [74, 24,  9, 70, 49, 61, 70, 54],\n",
      "        [51, 61, 86, 16, 99, 93, 12, 14],\n",
      "        [39, 79,  4, 84, 33, 17, 98, 79],\n",
      "        [19, 68,  8, 97, 55, 93, 65, 65],\n",
      "        [ 6, 56, 99, 23,  6, 93, 64,  1],\n",
      "        [39, 57, 27, 59, 85, 61, 49, 27],\n",
      "        [91, 28, 76, 47, 86, 95, 30, 19]])\n",
      "\n",
      "Padding mask:\n",
      "tensor([[0., 0., 0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "First 5 tokens of first sequence row 1:\n",
      "tensor([58,  6, 85, 54, 88])\n",
      "Next 3 tokens (should be 0s):\n",
      "tensor([0, 0, 0])\n",
      "\n",
      "First row padding for batch item 0:\n",
      "tensor([ 21,  17,  10,  78,  48, 999, 999, 999])\n",
      "\n",
      "First sequence mask (False=content, True=padding):\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(batch, semantic_pad_id: int):\n",
    "    \"\"\"\n",
    "    batch is a list of dicts: each dict has \"tokens\" shape [9, T],\n",
    "    and \"labels\" shape [9, T].\n",
    "    We pad them into [B, 9, T_max].\n",
    "    \"\"\"\n",
    "    max_input_len = max(item[\"tokens\"].shape[1] for item in batch)\n",
    "\n",
    "    B = len(batch)\n",
    "    # We'll create padded arrays:\n",
    "    tokens = torch.full((B, 9, max_input_len), 0, dtype=torch.long)  # 2=some <PAD>\n",
    "    tokens[:, 0, :] = semantic_pad_id\n",
    "    labels = torch.full(\n",
    "        (B, 9, max_input_len), -100, dtype=torch.long\n",
    "    )  # default is ignore_index\n",
    "\n",
    "    pad_mask = torch.ones(B, max_input_len)\n",
    "\n",
    "    for i, item in enumerate(batch):\n",
    "        seq_len = item[\"tokens\"].shape[1]\n",
    "        tokens[i, :, :seq_len] = item[\"tokens\"]\n",
    "        labels[i, :, :seq_len] = item[\"labels\"][:, :seq_len]\n",
    "        pad_mask[i, :seq_len] = False\n",
    "\n",
    "    return {\"tokens\": tokens, \"labels\": labels, \"pad_mask\": pad_mask}\n",
    "\n",
    "# Create two test sequences of different lengths\n",
    "seq1 = torch.randint(1, 100, (9, 5))  # Short sequence\n",
    "seq2 = torch.randint(1, 100, (9, 8))  # Longer sequence\n",
    "\n",
    "batch = [\n",
    "    {\"tokens\": seq1, \"labels\": seq1},\n",
    "    {\"tokens\": seq2, \"labels\": seq2}\n",
    "]\n",
    "\n",
    "# Test the collation\n",
    "semantic_pad_id = 999\n",
    "result = collate_fn(batch, semantic_pad_id)\n",
    "\n",
    "print(\"Tokens shape:\", result[\"tokens\"].shape)\n",
    "print(\"\\nFirst sequence tokens:\")\n",
    "print(result[\"tokens\"][0])\n",
    "print(\"\\nSecond sequence tokens:\")\n",
    "print(result[\"tokens\"][1])\n",
    "print(\"\\nPadding mask:\")\n",
    "print(result[\"pad_mask\"])\n",
    "\n",
    "# Let's verify:\n",
    "# 1. Sequences are left-aligned\n",
    "# 2. Padding is applied correctly\n",
    "# 3. Padding mask matches content\n",
    "\n",
    "# Check alignment of first sequence (should be at start)\n",
    "print(\"\\nFirst 5 tokens of first sequence row 1:\")\n",
    "print(result[\"tokens\"][0, 1, :5])\n",
    "print(\"Next 3 tokens (should be 0s):\")\n",
    "print(result[\"tokens\"][0, 1, 5:8])\n",
    "\n",
    "# Check padding of first row\n",
    "print(\"\\nFirst row padding for batch item 0:\")\n",
    "print(result[\"tokens\"][0, 0, :8])  # Should be semantic_pad_id\n",
    "\n",
    "# Check mask alignment\n",
    "print(\"\\nFirst sequence mask (False=content, True=padding):\")\n",
    "print(result[\"pad_mask\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting sequence lengths: 100%|██████████| 149658/149658 [01:09<00:00, 2150.41 examples/s]\n",
      "Finding maximum: 100%|██████████| 149658/149658 [01:20<00:00, 1859.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_length(example):\n",
    "    return {'length': example['labels'].shape[1]}\n",
    "\n",
    "max_len = 0\n",
    "def update_max(example):\n",
    "    global max_len\n",
    "    max_len = max(max_len, example['length'])\n",
    "    return example\n",
    "\n",
    "# Apply the transformations\n",
    "dataset[\"train\"].map(\n",
    "    get_length,\n",
    "    desc=\"Getting sequence lengths\"\n",
    ").map(\n",
    "    update_max,\n",
    "    desc=\"Finding maximum\"\n",
    ")\n",
    "\n",
    "print(f\"Maximum sequence length: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ratio: 0.442\n",
      "Std ratio: 0.139\n",
      "\n",
      "Percentile distribution:\n",
      "1th percentile: 0.089\n",
      "5th percentile: 0.189\n",
      "25th percentile: 0.366\n",
      "50th percentile: 0.455\n",
      "75th percentile: 0.515\n",
      "95th percentile: 0.691\n",
      "99th percentile: 0.816\n",
      "\n",
      "Found 521 outliers\n",
      "\n",
      "Sample of 5 outlier examples:\n",
      "\n",
      "Index 245\n",
      "Text (278 chars): The passers by were immediately struck with wonder....\n",
      "Sequence length: 318\n",
      "Ratio: 0.874\n",
      "\n",
      "Index 1426\n",
      "Text (285 chars): \"What would you suggest!\"...\n",
      "Sequence length: 330\n",
      "Ratio: 0.864\n",
      "\n",
      "Index 1446\n",
      "Text (368 chars): As he did so, Tad felt himself gradually sinking into the sombre depths....\n",
      "Sequence length: 426\n",
      "Ratio: 0.864\n",
      "\n",
      "Index 2947\n",
      "Text (371 chars): It had its points....\n",
      "Sequence length: 419\n",
      "Ratio: 0.885\n",
      "\n",
      "Index 2971\n",
      "Text (408 chars): No answer; though I allowed a more than decent interval....\n",
      "Sequence length: 474\n",
      "Ratio: 0.861\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get arrays from dataset\n",
    "text_lengths = np.array([len(x) for x in dataset[\"train\"]['normalized_text']])\n",
    "seq_lengths = np.array([x.shape[1] for x in dataset[\"train\"]['labels']])\n",
    "\n",
    "# Calculate ratios\n",
    "ratios = text_lengths / seq_lengths\n",
    "\n",
    "# Basic stats\n",
    "print(f\"Mean ratio: {ratios.mean():.3f}\")\n",
    "print(f\"Std ratio: {ratios.std():.3f}\")\n",
    "print(f\"\\nPercentile distribution:\")\n",
    "for p in [1, 5, 25, 50, 75, 95, 99]:\n",
    "    print(f\"{p}th percentile: {np.percentile(ratios, p):.3f}\")\n",
    "\n",
    "# Find extreme outliers (3 std from mean)\n",
    "mean, std = ratios.mean(), ratios.std()\n",
    "outliers = np.where(np.abs(ratios - mean) > 3 * std)[0]\n",
    "if len(outliers) > 0:\n",
    "    print(f\"\\nFound {len(outliers)} outliers\")\n",
    "    print(\"\\nSample of 5 outlier examples:\")\n",
    "    for idx in outliers[:5]:\n",
    "        print(f\"\\nIndex {int(idx)}\")  # Convert numpy int to Python int\n",
    "        print(f\"Text ({text_lengths[idx]} chars): {dataset['val'][int(idx)]['normalized_text'][:100]}...\")  # Convert idx\n",
    "        print(f\"Sequence length: {seq_lengths[idx]}\")\n",
    "        print(f\"Ratio: {ratios[idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWLINE_SEPARATOR = torch.tensor(tokenizer.encode(\"\\n\") + [0] * 8).unsqueeze(1)\n",
    "\n",
    "def batch_pack_sequences(examples, window_size=768, max_items=5):\n",
    "   \"\"\"\n",
    "   Pack sequences with system prompt and metrics\n",
    "   \"\"\"\n",
    "   packed_tokens = []\n",
    "   packed_labels = []\n",
    "   packed_speakers = []\n",
    "   pack_lengths = []\n",
    "   items_per_pack = []\n",
    "   \n",
    "   tokens = examples['tokens']\n",
    "   labels = examples['labels']\n",
    "   speakers = examples['speaker_id']\n",
    "   \n",
    "   # Account for system prompt in window size\n",
    "   effective_window = window_size - tts_sysprompt.shape[1]\n",
    "   \n",
    "   for i in range(len(tokens)):\n",
    "       seq_len = tokens[i].shape[1]\n",
    "       \n",
    "       # Start new pack\n",
    "       if i == 0 or current_length + seq_len > effective_window or \\\n",
    "          current_speaker != speakers[i] or current_items >= max_items:\n",
    "           \n",
    "           # Save previous pack if it exists\n",
    "           if i > 0 and current_tokens:\n",
    "               packed_tokens.append(torch.cat(current_tokens, dim=1))\n",
    "               packed_labels.append(torch.cat(current_labels, dim=1))\n",
    "               packed_speakers.append(current_speaker)\n",
    "               pack_lengths.append(current_length + tts_sysprompt.shape[1])\n",
    "               items_per_pack.append(current_items)\n",
    "           \n",
    "           # Initialize new pack with system prompt\n",
    "           current_tokens = [tts_sysprompt, tokens[i]]\n",
    "           current_labels = [tts_sysprompt, labels[i]]\n",
    "           current_speaker = speakers[i]\n",
    "           current_length = seq_len\n",
    "           current_items = 1\n",
    "           continue\n",
    "           \n",
    "       # Add to current pack with separator\n",
    "       current_tokens.extend([NEWLINE_SEPARATOR, tokens[i]])\n",
    "       current_labels.extend([NEWLINE_SEPARATOR, labels[i]])\n",
    "       current_length += seq_len + 1\n",
    "       current_items += 1\n",
    "   \n",
    "   # Don't forget last pack\n",
    "   if current_tokens:\n",
    "       packed_tokens.append(torch.cat(current_tokens, dim=1))\n",
    "       packed_labels.append(torch.cat(current_labels, dim=1))\n",
    "       packed_speakers.append(current_speaker)\n",
    "       pack_lengths.append(current_length + tts_sysprompt.shape[1])\n",
    "       items_per_pack.append(current_items)\n",
    "   \n",
    "   return {\n",
    "       'tokens': packed_tokens,\n",
    "       'labels': packed_labels,\n",
    "       'speaker_id': packed_speakers,\n",
    "       'pack_length': pack_lengths,\n",
    "       'items_in_pack': items_per_pack\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 149658/149658 [00:31<00:00, 4684.03 examples/s]\n",
      "Map: 100%|██████████| 5736/5736 [00:01<00:00, 4746.63 examples/s]\n",
      "Map: 100%|██████████| 4837/4837 [00:01<00:00, 4760.96 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "packed_dataset = dataset.map(\n",
    "    lambda row: batch_pack_sequences(row, max_items=3),\n",
    "    batched=True,\n",
    "    remove_columns=dataset['val'].column_names,\n",
    "    batch_size=1000  # Adjust based on memory constraints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nSpeak out the provided text<|im_end|>\\n<|im_start|>assistant\\n<|im_start|>user\\nThe weapon must still have been there.<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:1114|><|semantic:1609|><|semantic:784|><|semantic:499|><|semantic:260|><|semantic:1011|><|semantic:8|><|semantic:1407|><|semantic:540|><|semantic:1615|><|semantic:561|><|semantic:1945|><|semantic:201|><|semantic:1324|><|semantic:668|><|semantic:376|><|semantic:1849|><|semantic:9|><|semantic:1921|><|semantic:1921|><|semantic:1683|><|semantic:228|><|semantic:897|><|semantic:1677|><|semantic:518|><|im_end|>\\n<|im_start|>user\\nHow quickly he disappeared!\"<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1698|><|semantic:1848|><|semantic:1021|><|semantic:414|><|semantic:972|><|semantic:1252|><|semantic:1545|><|semantic:1363|><|semantic:307|><|semantic:722|><|semantic:1169|><|semantic:170|><|semantic:1701|><|semantic:1967|><|semantic:886|><|semantic:1540|><|semantic:1540|><|semantic:1113|><|semantic:902|><|semantic:1655|><|semantic:2009|><|semantic:56|><|semantic:1640|><|im_end|>\\n<|im_start|>user\\n\"But the blood?<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:503|><|semantic:1249|><|semantic:1039|><|semantic:1066|><|semantic:1522|><|semantic:680|><|semantic:1344|><|semantic:145|><|semantic:145|><|semantic:56|><|semantic:857|><|im_end|>\\n<|im_start|>user\\n\"So they tell me.\"<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:738|><|semantic:1669|><|semantic:1627|><|semantic:1144|><|semantic:578|><|semantic:847|><|semantic:184|><|semantic:1348|><|semantic:779|><|semantic:1715|><|semantic:658|><|semantic:141|><|semantic:844|><|im_end|>\\n<|im_start|>user\\nWhat do you make of it, Gryce?\"<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1415|><|semantic:167|><|semantic:1865|><|semantic:557|><|semantic:1000|><|semantic:49|><|semantic:1730|><|semantic:512|><|semantic:510|><|semantic:483|><|semantic:1352|><|semantic:1039|><|semantic:579|><|semantic:489|><|semantic:863|><|semantic:1388|><|semantic:874|><|semantic:632|><|semantic:527|><|semantic:1472|><|semantic:1602|><|semantic:1940|><|semantic:489|><|semantic:1331|><|im_end|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row = packed_dataset['val'][0]\n",
    "tokenizer.decode(example_row[\"tokens\"][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (5/5 shards): 100%|██████████| 50735/50735 [00:01<00:00, 33495.02 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1937/1937 [00:00<00:00, 33569.13 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1649/1649 [00:00<00:00, 31396.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "packed_dataset.save_to_disk(\"tokenized_libritts_packed_3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
