{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MimiModel, AutoFeatureExtractor\n",
    "\n",
    "device = \"cpu\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"kyutai/mimi\")\n",
    "model = MimiModel.from_pretrained(\"kyutai/mimi\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "def load_and_process_wav(file_path):\n",
    "    \"\"\"\n",
    "    Load a WAV file, convert it to mono, resample it to 24kHz, and return as a tensor.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the WAV file.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Processed audio tensor.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "    # Convert to mono if not already\n",
    "    if waveform.size(0) > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "    # Resample to 24kHz if needed\n",
    "    target_sample_rate = 24000\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def run_llama_generate(\n",
    "    text=\"Can you generate five simple sentences for my child to practice speaking\",\n",
    "    temp=0.1,\n",
    "    checkpoint_path=\"../dual-ar/checkpoints/smoltts_scratch/\",\n",
    "    working_dir=\"../../fish-speech.rs\"  # Replace with your desired working directory\n",
    "):\n",
    "    # Store current working directory\n",
    "    original_dir = os.getcwd()\n",
    "    \n",
    "    try:\n",
    "        # Change to desired working directory\n",
    "        os.chdir(working_dir)\n",
    "        \n",
    "        # Construct the command\n",
    "        cmd = f'cargo run --release --features cuda --bin llama_generate -- '\\\n",
    "              f'--text \"{text}\" '\\\n",
    "              f'--checkpoint {checkpoint_path} '\\\n",
    "              f'--temp {temp}'\n",
    "        \n",
    "        # Execute command\n",
    "        return os.system(cmd)\n",
    "        \n",
    "    finally:\n",
    "        # Always return to original directory\n",
    "        os.chdir(original_dir)\n",
    "\n",
    "# Example usage:\n",
    "# run_llama_generate(\n",
    "#     text=\"Write a short story about a cat\",\n",
    "#     temp=0.2,\n",
    "#     working_dir=\"/path/to/your/project\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# run_llama_generate(\n",
    "#     text=\"Here's how Bob talks, here's what language is, now speak like Bob saying this new thing\",\n",
    "#     temp=0.05\n",
    "# )\n",
    "# Load and process the data\n",
    "test_arr = np.load(\"../../out.npy\")\n",
    "test_input = torch.from_numpy(test_arr[:,:200]).to(device).to(torch.long)\n",
    "print(test_input.shape)\n",
    "\n",
    "# Generate audio\n",
    "out_pcm = model.decode(test_input)\n",
    "\n",
    "# Convert to CPU and get numpy array for playback\n",
    "audio_data = out_pcm.audio_values[0].detach().to(\"cpu\").numpy()\n",
    "\n",
    "# Create and display audio widget\n",
    "# Note: sample_rate=24000 matches your original save command\n",
    "display(Audio(audio_data, rate=24000, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pcm = load_and_process_wav(\"../../fish-speech.rs/voices/nova.wav\")\n",
    "codes = model.encode(pcm.to(\"cuda\").unsqueeze(0))\n",
    "np.save(\"nova.npy\", codes[\"audio_codes\"].squeeze(0)[:8, :].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes[\"audio_codes\"].squeeze(0)[:8,:].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
