{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritsuko/projects/ai/audio/dual-ar/.venv/lib/python3.9/site-packages/transformers/models/mimi/modeling_mimi.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, concatenate_datasets\n",
    "from transformers import MimiModel, AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"kyutai/mimi\")\n",
    "model = MimiModel.from_pretrained(\"kyutai/mimi\")\n",
    "model = model.to(\"mps\").eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: dataset creation script is elsewhere.\n",
    "\n",
    "If you are Jacob Keisling, please create a file `.env` in this repo and put your HuggingFace token under the `HUGGINGFACE_TOKEN=sk-xxxx` variable. Since you are probably not Jacob Keisling, if you want to re-upload, please pick a repo you actually own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 116.19ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 110.07ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 34/34 [00:00<00:00, 117.92ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 59/59 [00:00<00:00, 116.10ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 59/59 [00:00<00:00, 115.86ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jkeisling/libritts-r-mimi/commit/a7737c6e64509c17e366299a1597c58ee66dec10', commit_message='Upload dataset', commit_description='', oid='a7737c6e64509c17e366299a1597c58ee66dec10', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jkeisling/libritts-r-mimi', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jkeisling/libritts-r-mimi'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# If you created this from scratch\n",
    "dataset = load_from_disk(\"./encoded_libritts\")\n",
    "dataset = dataset.with_format(\"torch\")\n",
    "# Uncomment if this is your first time pushing your new dataset\n",
    "dataset.push_to_hub(\"jkeisling/libritts-r-mimi\", token=os.getenv(\"HUGGINGFACE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1049,  127, 1880, 1031, 1031, 1031, 1492, 1492, 1926, 1926, 1826, 1268,\n",
       "         1001,  382,  587,  178, 1380, 1380, 1790,  117,  130,  531, 2036,  722,\n",
       "         1470, 1725,  371,  728,  774, 1677,  518,  769,  666,   84,   84,  752,\n",
       "          752,  752,  752,  752, 1926, 1926, 1926, 1926],\n",
       "        [1700,  243,  243,  243,  243,  243, 1211,  243,  243,  243,  832, 1920,\n",
       "         1877, 1227, 1534,  860, 1576, 1984,  918, 1014, 1312, 2017,  104,  767,\n",
       "          605,  373, 1494,   93, 1284,  449, 1168, 1700,  243,  243,  243,  243,\n",
       "          243,  243,  243,  243,  243,  243,  243,  243],\n",
       "        [1626,  783, 1178, 1178, 1178, 1178, 1697, 1178, 1178, 1559,  783, 1989,\n",
       "         1982,   51, 1876, 1446, 1434, 1580,  256,   13,  470,  600,  105, 1936,\n",
       "         1727,  102, 1859,  487,  926,  959, 1033, 1178, 1178,  783, 1178, 1178,\n",
       "         1559, 1559, 1559, 1559, 1178, 1178, 1178, 1178],\n",
       "        [ 546,  546,  546,  290,  142,  164,  546,  290,  290,  164, 1225, 1911,\n",
       "          838,  214, 2036, 2007,  514,   58,  324, 1817, 1969, 1735,  997,  763,\n",
       "         1384,  710, 1514, 1439,  778,  682, 1233,  290,  546,  290,  546,  546,\n",
       "          546,  546,  164,  164,  290,  546,  546,  546],\n",
       "        [ 306,  481,  481, 1736,  481,  267, 1736, 1736, 1736, 1736,  589, 1357,\n",
       "          788, 1039,  540,  368, 1343, 1842, 2046, 1312,  279, 1656,   76, 1657,\n",
       "          555,  766, 1988,  969, 1109, 1136,  417,  481,  267, 1736,  267,  267,\n",
       "         1736, 1736,  267,  267, 1736,  481, 1736,  481],\n",
       "        [1443,  555, 1030, 1030, 1572, 1030, 1572, 1030, 1030, 1572, 1030,  886,\n",
       "         1687, 1667, 1077,  567, 1486, 1959, 1773,  449,  514,  124,  402, 2036,\n",
       "         1336, 1349,  755,  365,  245, 1336, 1568, 1443, 1030, 1030, 1030, 1030,\n",
       "         1572, 1030, 1443, 1443, 1030, 1030, 1572, 1572],\n",
       "        [1871,  666,  825,  666, 1978,  825, 1978,  666,  666,  666,  666, 1429,\n",
       "          150,  953,  299, 1954, 1812,  508,  611,  640,  314,   45, 1789,  106,\n",
       "         1696, 1271, 1202,  310, 1417,  557,  849, 1238, 1978,  666, 1978, 1978,\n",
       "         1978, 1978,  976,  976,  666,  825, 1978,  825],\n",
       "        [2008, 1648, 1744, 2008, 1648, 2008, 1648, 1648, 1648, 1744,  156, 1178,\n",
       "          978, 1242,  532, 1997, 1816, 1680,  769, 1623,  344, 1396, 1447, 1732,\n",
       "         1438,  413, 1684,   53, 1385, 1975, 1137, 1744, 2008, 2008, 2008, 2008,\n",
       "         1744, 1744, 1744, 1744, 1744, 2008, 2008, 2008]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "dataset = load_dataset(\"jkeisling/project-gutenberg-kokoro-2K\", token=os.getenv(\"HUGGINGFACE_ACCESS_TOKEN\"), streaming=False)\n",
    "dataset = dataset.with_format(\"torch\")\n",
    "codes = dataset[\"train\"][0]['codes']\n",
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_input = codes.to('mps').to(torch.long).unsqueeze(0)\n",
    "out_pcm = model.eval().decode(codes_input)\n",
    "torchaudio.save(\"out.wav\", out_pcm.audio_values[0].detach().to(\"cpu\"), 24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=6): 100%|██████████| 576820/576820 [00:28<00:00, 20049.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def add_length(example):\n",
    "    # Use .size(-1) if the code is a torch tensor; if it’s a list, use len()\n",
    "    example[\"audio_length\"] = int(example[\"codes\"].size(-1))\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(add_length, num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1291.7410)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset['train']['audio_length']) / 12.5 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text_normalized',\n",
       "  'codes',\n",
       "  'accent',\n",
       "  'gender',\n",
       "  'speaker_id',\n",
       "  'audio_length']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
