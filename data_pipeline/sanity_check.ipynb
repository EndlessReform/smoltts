{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,  9690,   198, 15024,   494,   578,   260,  2711,  1694,\n",
       "            2,   198,     1,  4093,   198,  1195,  6297,  1072,  2875,\n",
       "          338,   665,   359,  3260,   282,   260,  8399,  3736,  6568,\n",
       "          281,   260,  5267,    83,   903,   418, 26219,   527, 16547,\n",
       "         1767,  5189,    30,     2,   198,     1,   520,  9531,   198,\n",
       "        50147, 49543, 50206, 50366, 50992, 50959, 49365, 49333, 49289,\n",
       "        49448, 50164, 49832, 50155, 49625, 50930, 49525, 50764, 50203,\n",
       "        50203, 49901, 50898, 49164, 49332, 49332, 49282, 50573, 50573,\n",
       "        50367, 50576, 50729, 50732, 49390, 49237, 49562, 49749, 49518,\n",
       "        51149, 50119, 49999, 50732, 49237, 49158, 49635, 49503, 51033,\n",
       "        50261, 49594, 49364, 50776, 50955, 50137, 50010, 50496, 49251,\n",
       "        49251, 50382, 50325, 50322, 50966, 50667, 50728, 49987, 51042,\n",
       "        49800, 50838, 50874, 50874, 50807, 50405, 49180, 49712, 51043,\n",
       "        49158, 51017, 50094, 49253, 50493, 50636, 49264, 50718, 50754,\n",
       "        49949, 49949, 50759, 50527, 49724, 49724, 49479, 49631, 49351,\n",
       "        49351, 49683, 49768, 51068, 50754, 49486, 49902, 49415, 49834,\n",
       "        49797, 50849, 49775, 49787, 51155, 50962, 50477, 49731, 49949,\n",
       "        50483,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2],\n",
       "       [    0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          995,   391,  1054,  1214,  1840,  1807,   213,   181,   137,\n",
       "          296,  1012,   680,  1003,   473,  1778,   373,  1612,  1051,\n",
       "         1051,   749,  1746,    12,   180,   180,   130,  1421,  1421,\n",
       "         1215,  1424,  1577,  1580,   238,    85,   410,   597,   366,\n",
       "         1997,   967,   847,  1580,    85,     6,   483,   351,  1881,\n",
       "         1109,   442,   212,  1624,  1803,   985,   858,  1344,    99,\n",
       "           99,  1230,  1173,  1170,  1814,  1515,  1576,   835,  1890,\n",
       "          648,  1686,  1722,  1722,  1655,  1253,    28,   560,  1891,\n",
       "            6,  1865,   942,   101,  1341,  1484,   112,  1566,  1602,\n",
       "          797,   797,  1607,  1375,   572,   572,   327,   479,   199,\n",
       "          199,   531,   616,  1916,  1602,   334,   750,   263,   682,\n",
       "          645,  1697,   623,   635,  2003,  1810,  1325,   579,   797,\n",
       "         1331,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          748,   299,   908,   616,  1143,  2028,  1393,  1096,  1880,\n",
       "         1526,  1548,   895,  1297,  1222,   847,   926,   196,   487,\n",
       "          409,  1375,  1454,   936,   585,   507,   549,    39,   630,\n",
       "          355,   426,   127,    52,   534,  1974,   298,   629,  1052,\n",
       "         2008,   907,  1054,  1986,   463,  1313,  1354,   498,   478,\n",
       "          867,  1800,  1011,  1809,  1808,  2031,   272,   627,  1401,\n",
       "         1074,   830,   964,  1104,  1940,   818,  1050,  1056,   637,\n",
       "           50,  1967,  1978,   107,  1047,   454,    25,  1279,   317,\n",
       "          963,   907,  2027,   814,  2036,  2032,   963,     9,    90,\n",
       "          832,  1211,  1211,  1114,   253,  1537,  1744,  1040,   458,\n",
       "         1822,  1813,  1938,   355,   912,  1744,  1173,  1183,   133,\n",
       "         1434,  1789,  1983,  2026,   375,  1518,  1168,  1530,  1940,\n",
       "          316,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         1481,  1612,  1308,   235,  1445,    29,   162,    13,  1407,\n",
       "          105,   211,  1214,  1430,   307,   225,  1015,  1622,  1679,\n",
       "         1764,  1689,   407,  1612,   727,   897,   258,  1839,  1366,\n",
       "          211,  1445,  1159,   697,  1900,  1147,  1945,   597,  1047,\n",
       "          635,  1335,   687,  1821,  1689,   832,   505,  1334,  1135,\n",
       "          248,   533,  1491,  1712,  1509,  1449,  1510,   712,  1735,\n",
       "          277,  1302,   870,  1567,  1039,  1742,  1149,  1178,  1891,\n",
       "         2015,  2004,   290,   557,  1726,  1304,    14,  1404,  1644,\n",
       "          854,  1616,   738,  1767,   350,   220,   818,   211,  1499,\n",
       "         1315,  1315,  1559,  1071,  1255,   790,  1534,  1690,  1115,\n",
       "         1280,   775,  1836,   168,  1729,  1081,  1992,    60,  1214,\n",
       "          146,   598,  1716,  1769,   209,  1689,  1502,   377,  1599,\n",
       "         1016,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          130,   815,  1185,  1235,   372,   392,   289,   697,  2042,\n",
       "          956,   377,  1832,  1580,  1656,  1656,  1735,   293,   342,\n",
       "         1918,  1319,  1588,  1474,   608,  1260,  1581,   910,   418,\n",
       "          175,  1948,  1062,  1469,    11,   467,   909,   582,  1761,\n",
       "         1268,  1529,  1417,  1172,   317,  1957,   582,  1636,  2009,\n",
       "         1223,     4,   641,  1273,  1480,   656,  1261,  1779,  1107,\n",
       "          768,   355,  1954,   526,    97,   184,   390,    97,   126,\n",
       "         1064,   735,   416,   530,  1796,  1614,    59,   220,  1818,\n",
       "         1516,  1794,  1161,   280,  1586,   807,   857,  1543,  1894,\n",
       "         1712,   417,  1348,   411,  1058,  1601,   456,   422,  1236,\n",
       "         2042,  1595,  1231,   492,   667,   374,   112,   681,   320,\n",
       "         1868,  1993,   667,   536,    40,  1053,  1225,   175,   523,\n",
       "         1917,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         1471,   626,  1852,  1216,   136,  1926,  1282,  1885,    62,\n",
       "         1973,   736,  1424,   356,   991,  1600,   152,   609,  1479,\n",
       "         1239,   233,  1312,  1306,  1828,   521,   121,   285,  1488,\n",
       "         1523,  1641,  1163,  1961,  1930,    40,   115,   305,   749,\n",
       "          750,   701,  1869,   786,  1015,  1391,   764,   929,  1975,\n",
       "         1983,   679,  1547,  1927,  1038,   632,    44,   887,   141,\n",
       "          906,    95,  1142,   632,  1791,   381,   581,  1736,    82,\n",
       "         1228,   135,  1013,  1485,   714,  1944,   626,  1988,   960,\n",
       "          608,  1928,  1098,  2039,   643,  1792,  1706,   855,   885,\n",
       "           44,   142,   340,   439,   540,  1540,    20,   440,  1374,\n",
       "          765,  1152,   111,  1888,   885,   701,  1567,   626,   274,\n",
       "          439,   360,  1344,  1367,  1662,  1848,   819,  1988,  1616,\n",
       "          340,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          112,  1887,   457,   893,  1087,    26,   192,  1092,   322,\n",
       "          624,  1670,   235,  1437,   107,   885,    21,  1919,  1880,\n",
       "           31,   335,   832,   285,   233,   913,    54,  1161,  1403,\n",
       "          984,    91,  1629,  1403,   314,   291,  1555,   190,  1858,\n",
       "         1371,   580,   255,  1408,   163,  1158,  1312,  1206,  1785,\n",
       "          786,   628,  1962,  1351,   900,   156,  1684,   142,   376,\n",
       "          853,   443,   470,   482,  1198,  1147,  1572,  1572,   256,\n",
       "          157,   860,  1279,   353,   310,   470,   482,  1469,  1230,\n",
       "          419,   555,  1881,  1010,   247,   744,  1521,   936,  1545,\n",
       "         1948,  1443,  1443,  1232,   946,  1985,  2010,  1215,   665,\n",
       "          946,    29,  1403,   802,   573,   287,  1932,   848,  1549,\n",
       "         1571,    91,   322,  2012,  1402,   692,   726,  1015,  1099,\n",
       "         1443,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         1914,   269,    80,  1763,  1658,  1262,  1867,   936,   433,\n",
       "          850,  2020,   479,   387,   658,  1837,   450,  1082,  1945,\n",
       "         2030,  1737,  1572,   864,   489,   758,  1508,  1095,  1153,\n",
       "          364,  1397,    66,  1056,   395,  1712,  1684,  1242,   257,\n",
       "         1597,   119,   605,   146,   104,  1935,  1350,   717,  1778,\n",
       "          876,  1158,  1411,  2027,   194,  1824,    50,  1423,  1114,\n",
       "          728,    95,  1639,   645,   976,  1509,   183,   976,   536,\n",
       "         1338,   830,    58,  1051,    69,   948,  1508,  1273,  1736,\n",
       "         1331,  1238,  1616,  1963,   575,   528,   370,   879,  1497,\n",
       "           84,   477,  1238,  1246,  1724,    84,  1589,   929,  1547,\n",
       "          260,  1485,  1297,   519,  1018,  1643,   223,   665,  1114,\n",
       "         1457,   377,  1367,  1308,   610,   553,   428,   779,   183,\n",
       "          976,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          496,  1338,   602,   812,   353,  1467,  1567,  1338,  1895,\n",
       "          787,  1625,  1078,   645,  1473,  1763,    16,  1498,  1962,\n",
       "          321,   302,   935,   376,  1436,  1148,  1439,   848,   797,\n",
       "          119,   737,  1401,  1373,   545,  1261,   485,  1408,  1136,\n",
       "         1712,  1056,  1743,   842,  1861,  1867,   238,  1595,   747,\n",
       "         2028,  1065,  1767,   900,   832,  1177,   633,   426,  1813,\n",
       "         1239,   113,  1279,   270,  1548,  2008,  1137,  1273,   394,\n",
       "         1224,   636,  1315,   128,  1541,  1621,  1248,   305,  1418,\n",
       "           16,  1190,   531,   358,  1045,   482,  1401,   573,   948,\n",
       "          568,  1551,   156,  1829,  1970,    25,  1868,   368,  1932,\n",
       "         1982,   149,   149,   311,   843,  1853,  1403,  1578,  1817,\n",
       "         1273,  1871,   958,   767,  1704,  1052,   568,   583,  1551,\n",
       "         1744,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "arr = np.load(\"../train/tokens_batch_1.npy\")\n",
    "arr[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9, 172]), torch.Size([9, 171]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"tokenized_dataset\")\n",
    "dataset.shuffle(42)\n",
    "dataset[\"full\"][0][\"labels\"].shape, dataset[\"full\"][0][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Get max length in batch\n",
    "    max_input_len = max(x['tokens'].shape[1] for x in batch)\n",
    "    \n",
    "    # Prepare empty tensors for batch\n",
    "    tokens = torch.full((len(batch), 9, max_input_len), fill_value=2, dtype=torch.long)  # 2 for <|im_end|>\n",
    "    labels = torch.full((len(batch), 9, max_input_len + 1), fill_value=-100, dtype=torch.long)\n",
    "    \n",
    "    # Fill in actual values\n",
    "    for i, item in enumerate(batch):\n",
    "        seq_len = item['tokens'].shape[1]\n",
    "        tokens[i, :, :seq_len] = item['tokens'].clone().detach()\n",
    "        labels[i, :, :seq_len+1] = item['labels'].clone().detach()\n",
    "    \n",
    "    return {'tokens': tokens, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded text:\n",
      "<|im_start|>system\n",
      "Speak out the provided text<|im_end|>\n",
      "<|im_start|>user\n",
      "whence it deduced the practice and condition of every prison that replied.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<|semantic:1415|><|semantic:268|><|semantic:561|><|semantic:523|><|semantic:1300|><|semantic:942|><|semantic:170|><|semantic:1309|><|semantic:54|><|semantic:1269|><|semantic:1274|><|semantic:1326|><|semantic:1658|><|semantic:366|><|semantic:366|><|semantic:313|><|semantic:1899|><|semantic:146|><|semantic:238|><|semantic:1228|><|semantic:1534|><|semantic:300|><|semantic:1558|><|semantic:1054|><|semantic:1385|><|semantic:54|><|semantic:1379|><|semantic:1840|><|semantic:1517|><|semantic:410|><|semantic:1781|><|semantic:1508|><|semantic:552|><|semantic:1600|><|semantic:1600|><|semantic:1639|><|semantic:313|><|semantic:1997|><|semantic:1985|><|semantic:819|><|semantic:150|><|semantic:1487|><|semantic:1612|><|semantic:325|><|semantic:1910|><|semantic:858|><|semantic:157|><|semantic:157|><|semantic:839|><|semantic:1628|><|semantic:56|><|semantic:1640|><|semantic:769|><|semantic:666|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|>\n",
      "\n",
      "Shapes:\n",
      "Full batch shape: torch.Size([8, 9, 180])\n",
      "First item shape: torch.Size([9, 180])\n",
      "Semantic tokens shape: torch.Size([180])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../checkpoints/smoltts\")\n",
    "\n",
    "# Setup dataloader\n",
    "dataloader = DataLoader(dataset['full'], batch_size=8, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "# Get first batch\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "# Look at first item in batch\n",
    "first_item = batch['tokens'][0]  # Should be [9, seq_len]\n",
    "\n",
    "# Get semantic tokens (first row)\n",
    "semantic_tokens = first_item[0]  # Just the first index for semantic tokens\n",
    "\n",
    "# Remove padding (zeros) if any\n",
    "semantic_tokens = semantic_tokens[semantic_tokens != 0]\n",
    "\n",
    "# Decode\n",
    "decoded = tokenizer.decode(semantic_tokens)\n",
    "print(\"Decoded text:\")\n",
    "print(decoded)\n",
    "\n",
    "# Optional: print shapes to verify\n",
    "print(\"\\nShapes:\")\n",
    "print(f\"Full batch shape: {batch['tokens'].shape}\")\n",
    "print(f\"First item shape: {first_item.shape}\")\n",
    "print(f\"Semantic tokens shape: {semantic_tokens.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../checkpoints/smoltts, config: DualARModelArgs(model_type='dual_ar', vocab_size=51200, n_layer=30, n_head=9, dim=576, intermediate_size=1536, n_local_heads=3, head_dim=64, rope_base=100000, norm_eps=1e-05, max_seq_len=8192, dropout=0.0, tie_word_embeddings=True, attention_qkv_bias=False, codebook_size=2048, num_codebooks=8, use_gradient_checkpointing=True, initializer_range=0.041666666666666664, is_reward_model=False, share_codebook_embeddings=True, scale_codebook_embeddings=False, n_fast_layer=4, fast_dim=576, fast_n_head=9, fast_n_local_heads=3, fast_head_dim=64, fast_intermediate_size=1536, fast_attention_qkv_bias=False)\n",
      "Loaded weights with error: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "from model.dual_ar import DualARTransformer\n",
    "\n",
    "model = DualARTransformer.from_pretrained(\"../checkpoints/smoltts\", load_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSZ = 8\n",
    "len(dataset[\"full\"]) / BSZ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
