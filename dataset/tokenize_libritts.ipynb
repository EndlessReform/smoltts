{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize LibriTTS-R Mimi for target LM\n",
    "\n",
    "For our dataset, we currently simply use the Fish Speech TTS format:\n",
    "- Text-only data formatted using [ChatML](https://gist.github.com/edwardzjl/8df07c1f7140c9a3e2f48d33a8032090) as a separate sequence \"above\" the audio code stream\n",
    "- During sections where audio is being modeled, text stream 0 predicts the first semantic token index $n$ of the 8 Mimi residual codes as special token `<|semantic:n|>`\n",
    "- For audio, \"semantic\" (neural, there's not a strong distinction between) codes (from Mimi) padded with 0s during text sections\n",
    "\n",
    "It's possible this tokenization strategy can be improved, e.g. in [Defossez et al. 2024](https://arxiv.org/html/2410.00037v2#S3.SS4.SSS4) with the base transformer predicting the Whisper-timestamped word timings as an \"inner monologue\" and a delay between codebook timesteps. lol i'll do it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/audio/dual-ar/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, concatenate_datasets\n",
    "\n",
    "# If creating the libritts dataset for the first time\n",
    "# from datasets import load_from_disk \n",
    "# dataset = load_from_disk(\"encoded_dataset\")\n",
    "# train_clean_100 = load_from_disk(\"encoded_libritts/train.clean.100/\")\n",
    "# train_clean_360 = load_from_disk(\"encoded_libritts/train.clean.360/\")\n",
    "# dev_clean = load_from_disk(\"encoded_libritts/dev.clean\")\n",
    "# test_clean = load_from_disk(\"encoded_libritts/test.clean\")\n",
    "# full_train = concatenate_datasets([train_clean_100, train_clean_360])\n",
    "dataset = load_dataset(\"jkeisling/libritts-r-mimi\")\n",
    "full_train = concatenate_datasets([dataset[\"train.clean.100\"], dataset[\"train.clean.360\"]])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": full_train,\n",
    "    \"val\": dataset[\"dev.clean\"],\n",
    "    \"test\": dataset[\"test.clean\"]\n",
    "})\n",
    "dataset = dataset.with_format(\"torch\")\n",
    "dataset = dataset.remove_columns([\"path\", \"chapter_id\", \"text_original\"])\n",
    "dataset = dataset.rename_column(original_column_name=\"text_normalized\", new_column_name=\"normalized_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE! This is PATH DEPENDENT on ADDING THE SEMANTIC TOKENS TO THE TOKENIZER EARLIER using `create_smoltts_init.ipynb`. DO NOT SKIP THIS STEP OR THE MODEL WILL BE IRRETRIEVABLY BROKEN! YOU HAVE BEEN WARNED.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../checkpoints/smoltts_init\")\n",
    "tokenizer.use_default_system_prompt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this carefully: for SmolTTS, it should be 51200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51200, 49152)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer), tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please manually verify the text is done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalized_text': 'I felt it in my bones when I woke this morning that something splendid was going to turn up.',\n",
       " 'speaker_id': '4446',\n",
       " 'id': '4446_2275_000002_000009',\n",
       " 'codes': tensor([[1049, 1268,  549, 1324,  668, 1538, 1593,   95,  629, 1281, 1281,  680,\n",
       "           536,  536,  230, 1018, 1117,  244,  507,  997, 1399,  640, 1591, 1967,\n",
       "          1161,  690,   67, 1772,  830, 1612,  561,  119, 1052,  880, 1029, 1532,\n",
       "          1161, 1344, 1109,    6, 1001,  382,  596,   99, 1726, 2030,  531,  616,\n",
       "           367, 1271, 1868,  978,  729,  396, 1544],\n",
       "         [1470, 1879,  712,  283,  220,  137, 1610,  263,  531, 1845, 1428, 1132,\n",
       "           359, 1904, 1458, 1876,  895,  149,  190,  116,  603,  786, 1884, 1455,\n",
       "          1928,  677,  914, 1122,  436,  618,  850, 1766, 2005, 1618,  966,  850,\n",
       "          1663,  172,  274,  612, 1013, 1928, 1262, 1169, 1006, 1777, 1755, 2026,\n",
       "          1714,  788,  786, 1520,  811,   91, 1700],\n",
       "         [ 373,  602, 2016, 1148,   98,  790, 1570,  944, 1872,  807, 1427,  817,\n",
       "           602, 1090,  341, 1609,  774,  327,  479,  229, 1988, 1596, 1595,  339,\n",
       "          1801, 1360, 1415,  492,    3, 1064,  378, 1530,  800, 1369, 1331,  782,\n",
       "          1822,  511,  349, 1534, 1245, 1788,  146, 1195, 1510,  584, 1782,  662,\n",
       "          1523, 1523,   68, 2016, 1240,  783, 1178],\n",
       "         [1225, 1475,   17,  148,  656, 2036,  663,  632, 1926,  358, 1443,   33,\n",
       "          1316, 1993, 1038,  324, 1240,  861,  787, 1994, 1721,  832,  707,  435,\n",
       "           113,  138,  494,  920, 1707, 1134, 1003,  842, 1511,  193, 1936, 1478,\n",
       "          1261,  332,  756,  115, 1700,  324, 1074, 1631, 1575,  526, 1957,  756,\n",
       "           318,   19,  860, 1562,  164, 1477, 1450],\n",
       "         [ 457, 2035, 1113,  504, 1301,    5,  739,  334,  178, 1832, 1803,  266,\n",
       "          1719,  516,  147, 1016, 1402,  709, 1046, 1620,  440,  996,  100,  551,\n",
       "          1799, 1930, 1811, 1551, 1026, 1440,  684,  313,   13,  629, 1930,  723,\n",
       "           457,  328, 1455,  796,  300, 1610,  435,  635, 1517,  958, 1607, 1013,\n",
       "           911,  958,  524,  457, 1019, 1019,  481],\n",
       "         [1547,  592,  601, 2022, 1795,   42, 1631, 1174,  496, 1640,  935, 1687,\n",
       "           654, 1105,  668, 1995,  918, 1002, 1668,  190, 1148, 1509, 1563,   30,\n",
       "          1669,  882, 1529, 1794, 1086,  900,  274, 1001,  482,   42, 1852,  780,\n",
       "           704,  275, 1073, 1174, 1618, 1540, 1344, 1371,  263, 1245, 1382,  253,\n",
       "           484, 2044, 1717, 1942,  165, 1832,  478],\n",
       "         [1433, 1154, 1672,  879, 1683, 1529,  561,  508, 1648,  358,  646, 1289,\n",
       "          1307, 1867, 1937, 1076, 1694, 1730, 1199, 1758, 1476,  369,  801, 1249,\n",
       "           260, 1759,  740,   53,  618, 2023,  119,  835, 2015,  835,   66, 1209,\n",
       "          1285, 1744,  804, 1863, 1240,  392,  741, 1834, 1193, 1440, 1696, 1470,\n",
       "          1810, 1464,  840,   43, 1978,  666, 1978],\n",
       "         [ 948,  232, 1109, 1286, 1371,   94, 1516,  700,  714,  537, 1939,  334,\n",
       "            17, 1093, 1769, 1511, 1063,  444, 1399, 1594,   10,  532,  208, 1803,\n",
       "           945, 1193, 1082, 1667,  198,  382,  101, 1426,  458, 1587, 1450, 1722,\n",
       "          1173, 1286,  127,  225, 1482, 1368,  370, 1003, 1808, 1772,  952,  992,\n",
       "          1977,  820,  481,  945,  945, 1477, 1665]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tokenizer by encoding and decoding some example text\n",
    "example_text = \"This is a test sentence.\"\n",
    "encoded = tokenizer(example_text, return_tensors=\"pt\")\n",
    "decoded = tokenizer.decode(encoded['input_ids'][0])\n",
    "\n",
    "# Print the results\n",
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  4093,   198, 11449,   549,  2056,   744, 14538,   281,   451,\n",
       "          2583,     2,   198,     1,   520,  9531,   198]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": \"help me i am trapped in this computer\"}], add_generation_prompt=True,  return_tensors=\"pt\")\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>user\\nhelp me i am trapped in this computer<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sequence[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nTranscribe the provided speech<|im_end|>\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def encode_text(role: str, content: str, add_generation_prompt: bool = True) -> torch.Tensor:\n",
    "    # baseline = tokenizer.apply_chat_template(f\"{chr(10) if ''}<|im_start|>{role}\\n{content}<|im_end|>\\n\",)\n",
    "    baseline = tokenizer.apply_chat_template(\n",
    "        [{\"role\": role, \"content\": content}],\n",
    "        add_generation_prompt=add_generation_prompt,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    zeros_mask = torch.zeros(8, baseline.size(1), dtype=baseline.dtype)\n",
    "    return torch.cat([baseline, zeros_mask])\n",
    "\n",
    "tts_sysprompt = encode_text(\"system\", \"Speak out the provided text\")\n",
    "asr_sysprompt = encode_text(\"system\", \"Transcribe the provided speech\", False)\n",
    "tokenizer.decode(asr_sysprompt[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this assumes you're using ChatML. if you're NOT, then there's quite a bit more to fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|semantic:1049|><|semantic:1268|><|semantic:549|><|semantic:1324|><|semantic:668|><|semantic:1538|><|semantic:1593|><|semantic:95|><|semantic:629|><|semantic:1281|><|semantic:1281|><|semantic:680|><|semantic:536|><|semantic:536|><|semantic:230|><|semantic:1018|><|semantic:1117|><|semantic:244|><|semantic:507|><|semantic:997|><|semantic:1399|><|semantic:640|><|semantic:1591|><|semantic:1967|><|semantic:1161|><|semantic:690|><|semantic:67|><|semantic:1772|><|semantic:830|><|semantic:1612|><|semantic:561|><|semantic:119|><|semantic:1052|><|semantic:880|><|semantic:1029|><|semantic:1532|><|semantic:1161|><|semantic:1344|><|semantic:1109|><|semantic:6|><|semantic:1001|><|semantic:382|><|semantic:596|><|semantic:99|><|semantic:1726|><|semantic:2030|><|semantic:531|><|semantic:616|><|semantic:367|><|semantic:1271|><|semantic:1868|><|semantic:978|><|semantic:729|><|semantic:396|><|semantic:1544|><|im_end|>\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEMANTIC_OFFSET = tokenizer.encode(\"<|semantic:0|>\")[0]\n",
    "# B * C+1 * 2\n",
    "VQ_USER_PREFIX = encode_text(role=\"user\", content=\"\")[:,:-2]\n",
    "TRAILING_IM_END = torch.tensor([\n",
    "    tokenizer.encode(\"<|im_end|>\") + [0] * 8,\n",
    "    tokenizer.encode(\"\\n\") + [0] * 8,\n",
    "]).T\n",
    "\n",
    "def encode_vq(codes: torch.Tensor, is_assistant=True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Expects C * T\n",
    "    \"\"\"\n",
    "    if codes.ndim != 2:\n",
    "        raise ValueError(\"Must be single batch\")\n",
    "    speaker_line = codes[0,:] + SEMANTIC_OFFSET\n",
    "    vq_block = torch.cat([speaker_line.unsqueeze(0), codes])\n",
    "\n",
    "    block = torch.cat([vq_block, TRAILING_IM_END], dim=1)\n",
    "    return block if is_assistant else torch.cat([VQ_USER_PREFIX, block], dim=1)\n",
    "\n",
    "\n",
    "out = encode_vq(dataset[\"test\"][0][\"codes\"], is_assistant=True)\n",
    "tokenizer.decode(out[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user\\nI felt it in my bones when I woke this morning that something splendid was going to turn up.<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:1268|><|semantic:549|><|semantic:1324|><|semantic:668|><|semantic:1538|><|semantic:1593|><|semantic:95|><|semantic:629|><|semantic:1281|><|semantic:1281|><|semantic:680|><|semantic:536|><|semantic:536|><|semantic:230|><|semantic:1018|><|semantic:1117|><|semantic:244|><|semantic:507|><|semantic:997|><|semantic:1399|><|semantic:640|><|semantic:1591|><|semantic:1967|><|semantic:1161|><|semantic:690|><|semantic:67|><|semantic:1772|><|semantic:830|><|semantic:1612|><|semantic:561|><|semantic:119|><|semantic:1052|><|semantic:880|><|semantic:1029|><|semantic:1532|><|semantic:1161|><|semantic:1344|><|semantic:1109|><|semantic:6|><|semantic:1001|><|semantic:382|><|semantic:596|><|semantic:99|><|semantic:1726|><|semantic:2030|><|semantic:531|><|semantic:616|><|semantic:367|><|semantic:1271|><|semantic:1868|><|semantic:978|><|semantic:729|><|semantic:396|><|semantic:1544|><|im_end|>\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "# ASSISTANT_PREFIX_LEN = len(tokenizer.tokenize(\"<|im_start|>assistant\\n\"))\n",
    "# USER_PREFIX_LEN  = len(tokenizer.tokenize(\"<|im_start|>user\\n\"))\n",
    "\n",
    "# def tokenize_row(row: Dict, is_batch=True):\n",
    "#     \"\"\"\n",
    "#     row[\"normalized_text\"] is a string\n",
    "#     row[\"codes\"] is a torch.Tensor shaped [9, T_vq]\n",
    "#     \"\"\"\n",
    "#     row = {\n",
    "#         \"normalized_text\": row[\"normalized_text\"][0],\n",
    "#         \"codes\": row[\"codes\"][0],\n",
    "#         \"speaker_id\": row[\"speaker_id\"],\n",
    "#         \"id\": row[\"id\"]\n",
    "#     } if is_batch else row\n",
    "#     tts_user_line = encode_text(role=\"user\", content=row[\"normalized_text\"])\n",
    "#     asr_assistant_line = encode_text(role=\"assistant\", content=row[\"normalized_text\"], needs_initial_newline=True)\n",
    "#     tts_assistant_codes = encode_vq(row[\"codes\"])  # shape [9, T_vq]\n",
    "#     asr_user_codes = encode_vq(row[\"codes\"], is_assistant=False)  # shape [9, T_vq]\n",
    "    \n",
    "#     # Concatenate system prompt (row=1?), user line (row=1?), codebooks (row=9),\n",
    "#     # but along the *time* dimension => final shape [9, T_total] \n",
    "#     #   (since sysprompt and user_line are [1, T_something], \n",
    "#     #    codes_9rows is [9, T_vq], so we pad them to 9 rows if needed)\n",
    "#     # For demonstration, I'm just stacking them. You probably do:\n",
    "#     tts_ground_truth = torch.cat([tts_sysprompt, tts_user_line, tts_assistant_codes], dim=1)\n",
    "#     asr_ground_truth = torch.cat([asr_sysprompt, asr_user_codes, asr_assistant_line], dim=1)\n",
    "#     tts_tokens = tts_ground_truth[:,:-1].clone()\n",
    "#     asr_tokens = asr_ground_truth[:,:-1].clone()\n",
    "#     # Clone for labels\n",
    "#     tts_labels = tts_ground_truth[:, 1:].clone()\n",
    "#     asr_labels = asr_ground_truth[:, 1:].clone()\n",
    "\n",
    "#     # TTS MASKING (easy)\n",
    "#     # labels = asr_ground_truth[:, 1:].clone()\n",
    "#     # Let's define the \"text portion\" as sysprompt + user_line only\n",
    "#     text_len = tts_sysprompt.size(1) + tts_user_line.size(1) + ASSISTANT_PREFIX_LEN - 1  # no VQ_WRAPPER or codes\n",
    "#     # ONLY mask codebook rows for that text region\n",
    "#     # row=0 is your \"text\" row, row=1..8 might be codebooks, or vice versa\n",
    "#     # (Here I'm assuming row=0 is your actual text tokens. \n",
    "#     #  If it's reversed, tweak accordingly!)\n",
    "#     tts_labels[1:, :text_len] = -100\n",
    "\n",
    "#     asr_start_len = asr_sysprompt.size(1) + USER_PREFIX_LEN - 1\n",
    "#     asr_labels[1:, :asr_start_len] = -100\n",
    "#     asr_labels[1:, -asr_assistant_line.size(1):] = -100\n",
    "\n",
    "#     out = {\n",
    "#         \"tokens\": [tts_tokens, asr_tokens],\n",
    "#         \"labels\": [tts_labels, asr_labels],\n",
    "#         \"task\": [\"tts\", \"asr\"],\n",
    "#         \"normalized_text\": [row[\"normalized_text\"]] * 2,\n",
    "#         \"speaker_id\": row[\"speaker_id\"] * 2,\n",
    "#         \"id\": row[\"id\"] * 2,\n",
    "#     }\n",
    "#     return out\n",
    "\n",
    "# TODO: Not doing ASR for now\n",
    "def tts_tokenize_row(row: Dict):\n",
    "    \"\"\"\n",
    "    NOTE: Deliberately ignores sysprompt line for now, can be done in packing\n",
    "    \"\"\"\n",
    "    user_line = encode_text(role=\"user\", content=row[\"normalized_text\"], add_generation_prompt=True)\n",
    "    assistant_line = encode_vq(row[\"codes\"])\n",
    "    ground_truth = torch.cat([user_line, assistant_line], dim=1)\n",
    "    # Causal shift\n",
    "    tokens = ground_truth[:,:-1].clone()\n",
    "    labels = ground_truth[:,1:].clone()\n",
    "\n",
    "    # Assuming user line took care of assistant prefix\n",
    "    labels[1:, :user_line.size(1) - 1] = -100\n",
    "    # Mask out newline\n",
    "    labels[1:, -1] = -100\n",
    "\n",
    "    return({\n",
    "        \"tokens\": tokens,\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    \n",
    "\n",
    "\n",
    "example_row = tts_tokenize_row(dataset[\"test\"][0])\n",
    "tokenizer.decode(example_row[\"labels\"][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4093,   198,    57,  4592,   357,   281,   957,  6542,   645,   339,\n",
       "         40652,   451,  5738,   338,  1488, 33494,   436,  2045,   288,  1607,\n",
       "           614,    30,     2,   198,     1,   520,  9531,   198, 50201, 50420,\n",
       "         49701, 50476, 49820, 50690, 50745, 49247, 49781, 50433, 50433, 49832,\n",
       "         49688, 49688, 49382, 50170, 50269, 49396, 49659, 50149, 50551, 49792,\n",
       "         50743, 51119, 50313, 49842, 49219, 50924, 49982, 50764, 49713, 49271,\n",
       "         50204, 50032, 50181, 50684, 50313, 50496, 50261, 49158, 50153, 49534,\n",
       "         49748, 49251, 50878, 51182, 49683, 49768, 49519, 50423, 51020, 50130,\n",
       "         49881, 49548, 50696,     2,   198],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1049,  1268,\n",
       "           549,  1324,   668,  1538,  1593,    95,   629,  1281,  1281,   680,\n",
       "           536,   536,   230,  1018,  1117,   244,   507,   997,  1399,   640,\n",
       "          1591,  1967,  1161,   690,    67,  1772,   830,  1612,   561,   119,\n",
       "          1052,   880,  1029,  1532,  1161,  1344,  1109,     6,  1001,   382,\n",
       "           596,    99,  1726,  2030,   531,   616,   367,  1271,  1868,   978,\n",
       "           729,   396,  1544,     0,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1470,  1879,\n",
       "           712,   283,   220,   137,  1610,   263,   531,  1845,  1428,  1132,\n",
       "           359,  1904,  1458,  1876,   895,   149,   190,   116,   603,   786,\n",
       "          1884,  1455,  1928,   677,   914,  1122,   436,   618,   850,  1766,\n",
       "          2005,  1618,   966,   850,  1663,   172,   274,   612,  1013,  1928,\n",
       "          1262,  1169,  1006,  1777,  1755,  2026,  1714,   788,   786,  1520,\n",
       "           811,    91,  1700,     0,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   373,   602,\n",
       "          2016,  1148,    98,   790,  1570,   944,  1872,   807,  1427,   817,\n",
       "           602,  1090,   341,  1609,   774,   327,   479,   229,  1988,  1596,\n",
       "          1595,   339,  1801,  1360,  1415,   492,     3,  1064,   378,  1530,\n",
       "           800,  1369,  1331,   782,  1822,   511,   349,  1534,  1245,  1788,\n",
       "           146,  1195,  1510,   584,  1782,   662,  1523,  1523,    68,  2016,\n",
       "          1240,   783,  1178,     0,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1225,  1475,\n",
       "            17,   148,   656,  2036,   663,   632,  1926,   358,  1443,    33,\n",
       "          1316,  1993,  1038,   324,  1240,   861,   787,  1994,  1721,   832,\n",
       "           707,   435,   113,   138,   494,   920,  1707,  1134,  1003,   842,\n",
       "          1511,   193,  1936,  1478,  1261,   332,   756,   115,  1700,   324,\n",
       "          1074,  1631,  1575,   526,  1957,   756,   318,    19,   860,  1562,\n",
       "           164,  1477,  1450,     0,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   457,  2035,\n",
       "          1113,   504,  1301,     5,   739,   334,   178,  1832,  1803,   266,\n",
       "          1719,   516,   147,  1016,  1402,   709,  1046,  1620,   440,   996,\n",
       "           100,   551,  1799,  1930,  1811,  1551,  1026,  1440,   684,   313,\n",
       "            13,   629,  1930,   723,   457,   328,  1455,   796,   300,  1610,\n",
       "           435,   635,  1517,   958,  1607,  1013,   911,   958,   524,   457,\n",
       "          1019,  1019,   481,     0,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1547,   592,\n",
       "           601,  2022,  1795,    42,  1631,  1174,   496,  1640,   935,  1687,\n",
       "           654,  1105,   668,  1995,   918,  1002,  1668,   190,  1148,  1509,\n",
       "          1563,    30,  1669,   882,  1529,  1794,  1086,   900,   274,  1001,\n",
       "           482,    42,  1852,   780,   704,   275,  1073,  1174,  1618,  1540,\n",
       "          1344,  1371,   263,  1245,  1382,   253,   484,  2044,  1717,  1942,\n",
       "           165,  1832,   478,     0,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1433,  1154,\n",
       "          1672,   879,  1683,  1529,   561,   508,  1648,   358,   646,  1289,\n",
       "          1307,  1867,  1937,  1076,  1694,  1730,  1199,  1758,  1476,   369,\n",
       "           801,  1249,   260,  1759,   740,    53,   618,  2023,   119,   835,\n",
       "          2015,   835,    66,  1209,  1285,  1744,   804,  1863,  1240,   392,\n",
       "           741,  1834,  1193,  1440,  1696,  1470,  1810,  1464,   840,    43,\n",
       "          1978,   666,  1978,     0,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   948,   232,\n",
       "          1109,  1286,  1371,    94,  1516,   700,   714,   537,  1939,   334,\n",
       "            17,  1093,  1769,  1511,  1063,   444,  1399,  1594,    10,   532,\n",
       "           208,  1803,   945,  1193,  1082,  1667,   198,   382,   101,  1426,\n",
       "           458,  1587,  1450,  1722,  1173,  1286,   127,   225,  1482,  1368,\n",
       "           370,  1003,  1808,  1772,   952,   992,  1977,   820,   481,   945,\n",
       "           945,  1477,  1665,     0,  -100]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/149658 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 149658/149658 [01:34<00:00, 1578.78 examples/s]\n",
      "Map: 100%|██████████| 5736/5736 [00:03<00:00, 1566.43 examples/s]\n",
      "Map: 100%|██████████| 4837/4837 [00:03<00:00, 1531.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# DO NOT INCREASE batch size\n",
    "dataset = dataset.map(tts_tokenize_row, remove_columns=\"codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWLINE_SEPARATOR = torch.tensor(tokenizer.encode(\"\\n\") + [0] * 8).unsqueeze(1)\n",
    "\n",
    "def batch_pack_sequences(examples, window_size=768, max_items=5):\n",
    "   \"\"\"\n",
    "   Pack sequences with system prompt and metrics\n",
    "   \"\"\"\n",
    "   packed_tokens = []\n",
    "   packed_labels = []\n",
    "   packed_speakers = []\n",
    "   pack_lengths = []\n",
    "   items_per_pack = []\n",
    "   \n",
    "   tokens = examples['tokens']\n",
    "   labels = examples['labels']\n",
    "   speakers = examples['speaker_id']\n",
    "   \n",
    "   # Account for system prompt in window size\n",
    "   effective_window = window_size - tts_sysprompt.shape[1]\n",
    "   \n",
    "   for i in range(len(tokens)):\n",
    "       seq_len = tokens[i].shape[1]\n",
    "       \n",
    "       # Start new pack\n",
    "       if i == 0 or current_length + seq_len > effective_window or \\\n",
    "          current_speaker != speakers[i] or current_items >= max_items:\n",
    "           \n",
    "           # Save previous pack if it exists\n",
    "           if i > 0 and current_tokens:\n",
    "               packed_tokens.append(torch.cat(current_tokens, dim=1))\n",
    "               packed_labels.append(torch.cat(current_labels, dim=1))\n",
    "               packed_speakers.append(current_speaker)\n",
    "               pack_lengths.append(current_length + tts_sysprompt.shape[1])\n",
    "               items_per_pack.append(current_items)\n",
    "           \n",
    "           # Initialize new pack with system prompt\n",
    "           current_tokens = [tts_sysprompt, tokens[i]]\n",
    "           current_labels = [tts_sysprompt, labels[i]]\n",
    "           current_speaker = speakers[i]\n",
    "           current_length = seq_len\n",
    "           current_items = 1\n",
    "           continue\n",
    "           \n",
    "       # Add to current pack with separator\n",
    "       current_tokens.extend([NEWLINE_SEPARATOR, tokens[i]])\n",
    "       current_labels.extend([NEWLINE_SEPARATOR, labels[i]])\n",
    "       current_length += seq_len + 1\n",
    "       current_items += 1\n",
    "   \n",
    "   # Don't forget last pack\n",
    "   if current_tokens:\n",
    "       packed_tokens.append(torch.cat(current_tokens, dim=1))\n",
    "       packed_labels.append(torch.cat(current_labels, dim=1))\n",
    "       packed_speakers.append(current_speaker)\n",
    "       pack_lengths.append(current_length + tts_sysprompt.shape[1])\n",
    "       items_per_pack.append(current_items)\n",
    "   \n",
    "   return {\n",
    "       'tokens': packed_tokens,\n",
    "       'labels': packed_labels,\n",
    "       'speaker_id': packed_speakers,\n",
    "       'pack_length': pack_lengths,\n",
    "       'items_in_pack': items_per_pack\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 149658/149658 [00:31<00:00, 4684.03 examples/s]\n",
      "Map: 100%|██████████| 5736/5736 [00:01<00:00, 4746.63 examples/s]\n",
      "Map: 100%|██████████| 4837/4837 [00:01<00:00, 4760.96 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "packed_dataset = dataset.map(\n",
    "    lambda row: batch_pack_sequences(row, max_items=3),\n",
    "    batched=True,\n",
    "    remove_columns=dataset['val'].column_names,\n",
    "    batch_size=1000  # Adjust based on memory constraints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nSpeak out the provided text<|im_end|>\\n<|im_start|>assistant\\n<|im_start|>user\\nThe weapon must still have been there.<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:1114|><|semantic:1609|><|semantic:784|><|semantic:499|><|semantic:260|><|semantic:1011|><|semantic:8|><|semantic:1407|><|semantic:540|><|semantic:1615|><|semantic:561|><|semantic:1945|><|semantic:201|><|semantic:1324|><|semantic:668|><|semantic:376|><|semantic:1849|><|semantic:9|><|semantic:1921|><|semantic:1921|><|semantic:1683|><|semantic:228|><|semantic:897|><|semantic:1677|><|semantic:518|><|im_end|>\\n<|im_start|>user\\nHow quickly he disappeared!\"<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1698|><|semantic:1848|><|semantic:1021|><|semantic:414|><|semantic:972|><|semantic:1252|><|semantic:1545|><|semantic:1363|><|semantic:307|><|semantic:722|><|semantic:1169|><|semantic:170|><|semantic:1701|><|semantic:1967|><|semantic:886|><|semantic:1540|><|semantic:1540|><|semantic:1113|><|semantic:902|><|semantic:1655|><|semantic:2009|><|semantic:56|><|semantic:1640|><|im_end|>\\n<|im_start|>user\\n\"But the blood?<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:503|><|semantic:1249|><|semantic:1039|><|semantic:1066|><|semantic:1522|><|semantic:680|><|semantic:1344|><|semantic:145|><|semantic:145|><|semantic:56|><|semantic:857|><|im_end|>\\n<|im_start|>user\\n\"So they tell me.\"<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:738|><|semantic:1669|><|semantic:1627|><|semantic:1144|><|semantic:578|><|semantic:847|><|semantic:184|><|semantic:1348|><|semantic:779|><|semantic:1715|><|semantic:658|><|semantic:141|><|semantic:844|><|im_end|>\\n<|im_start|>user\\nWhat do you make of it, Gryce?\"<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1415|><|semantic:167|><|semantic:1865|><|semantic:557|><|semantic:1000|><|semantic:49|><|semantic:1730|><|semantic:512|><|semantic:510|><|semantic:483|><|semantic:1352|><|semantic:1039|><|semantic:579|><|semantic:489|><|semantic:863|><|semantic:1388|><|semantic:874|><|semantic:632|><|semantic:527|><|semantic:1472|><|semantic:1602|><|semantic:1940|><|semantic:489|><|semantic:1331|><|im_end|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row = packed_dataset['val'][0]\n",
    "tokenizer.decode(example_row[\"tokens\"][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (5/5 shards): 100%|██████████| 50735/50735 [00:01<00:00, 33495.02 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1937/1937 [00:00<00:00, 33569.13 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1649/1649 [00:00<00:00, 31396.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "packed_dataset.save_to_disk(\"tokenized_libritts_packed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'system\\nSpeak out the provided text<|im_end|>\\n<|im_start|>user\\nI felt it in my bones when I woke this morning that something splendid was going to turn up.<|im_end|>\\n<|im_start|>assistant\\n<|semantic:1049|><|semantic:1268|><|semantic:549|><|semantic:1324|><|semantic:668|><|semantic:1538|><|semantic:1593|><|semantic:95|><|semantic:629|><|semantic:1281|><|semantic:1281|><|semantic:680|><|semantic:536|><|semantic:536|><|semantic:230|><|semantic:1018|><|semantic:1117|><|semantic:244|><|semantic:507|><|semantic:997|><|semantic:1399|><|semantic:640|><|semantic:1591|><|semantic:1967|><|semantic:1161|><|semantic:690|><|semantic:67|><|semantic:1772|><|semantic:830|><|semantic:1612|><|semantic:561|><|semantic:119|><|semantic:1052|><|semantic:880|><|semantic:1029|><|semantic:1532|><|semantic:1161|><|semantic:1344|><|semantic:1109|><|semantic:6|><|semantic:1001|><|semantic:382|><|semantic:596|><|semantic:99|><|semantic:1726|><|semantic:2030|><|semantic:531|><|semantic:616|><|semantic:367|><|semantic:1271|><|semantic:1868|><|semantic:978|><|semantic:729|><|semantic:396|><|semantic:1544|><|im_end|>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example_row[0][\"labels\"][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'system\\nTranscribe the provided speech<|im_end|>\\n<|im_start|>user\\n<|semantic:1049|><|semantic:1268|><|semantic:549|><|semantic:1324|><|semantic:668|><|semantic:1538|><|semantic:1593|><|semantic:95|><|semantic:629|><|semantic:1281|><|semantic:1281|><|semantic:680|><|semantic:536|><|semantic:536|><|semantic:230|><|semantic:1018|><|semantic:1117|><|semantic:244|><|semantic:507|><|semantic:997|><|semantic:1399|><|semantic:640|><|semantic:1591|><|semantic:1967|><|semantic:1161|><|semantic:690|><|semantic:67|><|semantic:1772|><|semantic:830|><|semantic:1612|><|semantic:561|><|semantic:119|><|semantic:1052|><|semantic:880|><|semantic:1029|><|semantic:1532|><|semantic:1161|><|semantic:1344|><|semantic:1109|><|semantic:6|><|semantic:1001|><|semantic:382|><|semantic:596|><|semantic:99|><|semantic:1726|><|semantic:2030|><|semantic:531|><|semantic:616|><|semantic:367|><|semantic:1271|><|semantic:1868|><|semantic:978|><|semantic:729|><|semantic:396|><|semantic:1544|><|im_end|>\\n<|im_start|>assistant\\nI felt it in my bones when I woke this morning that something splendid was going to turn up.<|im_end|>\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example_row[1][\"labels\"][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0, 1698, 1719,  204, 1389,  851, 1772,  186, 1307, 1895,  832,\n",
       "        1633,  771,  648, 1530, 1989, 1574, 1348,  722,  144, 1945,  278, 1109,\n",
       "          29,  611,   46,  622,  628, 1740,  572,  572,  345, 1989, 1676,  929,\n",
       "        1776,  749,  313, 1997, 1571,  819, 1238, 1054, 1054, 1135, 1506, 1393,\n",
       "         616, 1702,  993,  579,  486,  486, 2039,  148,  657,  664,  339,  339,\n",
       "         588,  212, 1443,   32, 1320, 1549,  440,    8, 1407, 1722, 1650, 1615,\n",
       "         798,  121,  303,  697,  837,  358, 1882,  440, 1992, 1992,  587,  178,\n",
       "         178, 1627, 1530,  929, 1610, 1916,  523,  213, 1252, 1480, 1468, 1899,\n",
       "         773, 2033, 2033,   83, 1146,  784, 1295,  199, 1109,  268,    6,    6,\n",
       "        1781, 1479, 1530, 1530,  146, 2038,  984, 1403,  606, 1379, 1840, 1172,\n",
       "        1680, 1162, 1928])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row[\"tokens\"][0][1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, 1049, 1268,  549, 1324,  668, 1538, 1593,   95,  629, 1281, 1281,\n",
       "         680,  536,  536,  230, 1018, 1117,  244,  507,  997, 1399,  640, 1591,\n",
       "        1967, 1161,  690,   67, 1772,  830, 1612,  561,  119, 1052,  880, 1029,\n",
       "        1532, 1161, 1344, 1109,    6, 1001,  382,  596,   99, 1726, 2030,  531,\n",
       "         616,  367, 1271, 1868,  978,  729,  396, 1544,    0, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row[1][\"labels\"][1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalized_text': 'I felt it in my bones when I woke this morning that something splendid was going to turn up.',\n",
       " 'speaker_id': '4446',\n",
       " 'id': '4446_2275_000002_000009',\n",
       " 'tokens': tensor([[    1,  9690,   198, 15024,   494,   578,   260,  2711,  1694,     2,\n",
       "            198,     1,  4093,   198,    57,  4592,   357,   281,   957,  6542,\n",
       "            645,   339, 40652,   451,  5738,   338,  1488, 33494,   436,  2045,\n",
       "            288,  1607,   614,    30,     2,   198,     1,   520,  9531,   198,\n",
       "          50201, 50420, 49701, 50476, 49820, 50690, 50745, 49247, 49781, 50433,\n",
       "          50433, 49832, 49688, 49688, 49382, 50170, 50269, 49396, 49659, 50149,\n",
       "          50551, 49792, 50743, 51119, 50313, 49842, 49219, 50924, 49982, 50764,\n",
       "          49713, 49271, 50204, 50032, 50181, 50684, 50313, 50496, 50261, 49158,\n",
       "          50153, 49534, 49748, 49251, 50878, 51182, 49683, 49768, 49519, 50423,\n",
       "          51020, 50130, 49881, 49548, 50696],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           1049,  1268,   549,  1324,   668,  1538,  1593,    95,   629,  1281,\n",
       "           1281,   680,   536,   536,   230,  1018,  1117,   244,   507,   997,\n",
       "           1399,   640,  1591,  1967,  1161,   690,    67,  1772,   830,  1612,\n",
       "            561,   119,  1052,   880,  1029,  1532,  1161,  1344,  1109,     6,\n",
       "           1001,   382,   596,    99,  1726,  2030,   531,   616,   367,  1271,\n",
       "           1868,   978,   729,   396,  1544],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           1470,  1879,   712,   283,   220,   137,  1610,   263,   531,  1845,\n",
       "           1428,  1132,   359,  1904,  1458,  1876,   895,   149,   190,   116,\n",
       "            603,   786,  1884,  1455,  1928,   677,   914,  1122,   436,   618,\n",
       "            850,  1766,  2005,  1618,   966,   850,  1663,   172,   274,   612,\n",
       "           1013,  1928,  1262,  1169,  1006,  1777,  1755,  2026,  1714,   788,\n",
       "            786,  1520,   811,    91,  1700],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            373,   602,  2016,  1148,    98,   790,  1570,   944,  1872,   807,\n",
       "           1427,   817,   602,  1090,   341,  1609,   774,   327,   479,   229,\n",
       "           1988,  1596,  1595,   339,  1801,  1360,  1415,   492,     3,  1064,\n",
       "            378,  1530,   800,  1369,  1331,   782,  1822,   511,   349,  1534,\n",
       "           1245,  1788,   146,  1195,  1510,   584,  1782,   662,  1523,  1523,\n",
       "             68,  2016,  1240,   783,  1178],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           1225,  1475,    17,   148,   656,  2036,   663,   632,  1926,   358,\n",
       "           1443,    33,  1316,  1993,  1038,   324,  1240,   861,   787,  1994,\n",
       "           1721,   832,   707,   435,   113,   138,   494,   920,  1707,  1134,\n",
       "           1003,   842,  1511,   193,  1936,  1478,  1261,   332,   756,   115,\n",
       "           1700,   324,  1074,  1631,  1575,   526,  1957,   756,   318,    19,\n",
       "            860,  1562,   164,  1477,  1450],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            457,  2035,  1113,   504,  1301,     5,   739,   334,   178,  1832,\n",
       "           1803,   266,  1719,   516,   147,  1016,  1402,   709,  1046,  1620,\n",
       "            440,   996,   100,   551,  1799,  1930,  1811,  1551,  1026,  1440,\n",
       "            684,   313,    13,   629,  1930,   723,   457,   328,  1455,   796,\n",
       "            300,  1610,   435,   635,  1517,   958,  1607,  1013,   911,   958,\n",
       "            524,   457,  1019,  1019,   481],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           1547,   592,   601,  2022,  1795,    42,  1631,  1174,   496,  1640,\n",
       "            935,  1687,   654,  1105,   668,  1995,   918,  1002,  1668,   190,\n",
       "           1148,  1509,  1563,    30,  1669,   882,  1529,  1794,  1086,   900,\n",
       "            274,  1001,   482,    42,  1852,   780,   704,   275,  1073,  1174,\n",
       "           1618,  1540,  1344,  1371,   263,  1245,  1382,   253,   484,  2044,\n",
       "           1717,  1942,   165,  1832,   478],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           1433,  1154,  1672,   879,  1683,  1529,   561,   508,  1648,   358,\n",
       "            646,  1289,  1307,  1867,  1937,  1076,  1694,  1730,  1199,  1758,\n",
       "           1476,   369,   801,  1249,   260,  1759,   740,    53,   618,  2023,\n",
       "            119,   835,  2015,   835,    66,  1209,  1285,  1744,   804,  1863,\n",
       "           1240,   392,   741,  1834,  1193,  1440,  1696,  1470,  1810,  1464,\n",
       "            840,    43,  1978,   666,  1978],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            948,   232,  1109,  1286,  1371,    94,  1516,   700,   714,   537,\n",
       "           1939,   334,    17,  1093,  1769,  1511,  1063,   444,  1399,  1594,\n",
       "             10,   532,   208,  1803,   945,  1193,  1082,  1667,   198,   382,\n",
       "            101,  1426,   458,  1587,  1450,  1722,  1173,  1286,   127,   225,\n",
       "           1482,  1368,   370,  1003,  1808,  1772,   952,   992,  1977,   820,\n",
       "            481,   945,   945,  1477,  1665]]),\n",
       " 'labels': tensor([[ 9690,   198, 15024,   494,   578,   260,  2711,  1694,     2,   198,\n",
       "              1,  4093,   198,    57,  4592,   357,   281,   957,  6542,   645,\n",
       "            339, 40652,   451,  5738,   338,  1488, 33494,   436,  2045,   288,\n",
       "           1607,   614,    30,     2,   198,     1,   520,  9531,   198, 50201,\n",
       "          50420, 49701, 50476, 49820, 50690, 50745, 49247, 49781, 50433, 50433,\n",
       "          49832, 49688, 49688, 49382, 50170, 50269, 49396, 49659, 50149, 50551,\n",
       "          49792, 50743, 51119, 50313, 49842, 49219, 50924, 49982, 50764, 49713,\n",
       "          49271, 50204, 50032, 50181, 50684, 50313, 50496, 50261, 49158, 50153,\n",
       "          49534, 49748, 49251, 50878, 51182, 49683, 49768, 49519, 50423, 51020,\n",
       "          50130, 49881, 49548, 50696,     2],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1049,\n",
       "           1268,   549,  1324,   668,  1538,  1593,    95,   629,  1281,  1281,\n",
       "            680,   536,   536,   230,  1018,  1117,   244,   507,   997,  1399,\n",
       "            640,  1591,  1967,  1161,   690,    67,  1772,   830,  1612,   561,\n",
       "            119,  1052,   880,  1029,  1532,  1161,  1344,  1109,     6,  1001,\n",
       "            382,   596,    99,  1726,  2030,   531,   616,   367,  1271,  1868,\n",
       "            978,   729,   396,  1544,     0],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1470,\n",
       "           1879,   712,   283,   220,   137,  1610,   263,   531,  1845,  1428,\n",
       "           1132,   359,  1904,  1458,  1876,   895,   149,   190,   116,   603,\n",
       "            786,  1884,  1455,  1928,   677,   914,  1122,   436,   618,   850,\n",
       "           1766,  2005,  1618,   966,   850,  1663,   172,   274,   612,  1013,\n",
       "           1928,  1262,  1169,  1006,  1777,  1755,  2026,  1714,   788,   786,\n",
       "           1520,   811,    91,  1700,     0],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   373,\n",
       "            602,  2016,  1148,    98,   790,  1570,   944,  1872,   807,  1427,\n",
       "            817,   602,  1090,   341,  1609,   774,   327,   479,   229,  1988,\n",
       "           1596,  1595,   339,  1801,  1360,  1415,   492,     3,  1064,   378,\n",
       "           1530,   800,  1369,  1331,   782,  1822,   511,   349,  1534,  1245,\n",
       "           1788,   146,  1195,  1510,   584,  1782,   662,  1523,  1523,    68,\n",
       "           2016,  1240,   783,  1178,     0],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1225,\n",
       "           1475,    17,   148,   656,  2036,   663,   632,  1926,   358,  1443,\n",
       "             33,  1316,  1993,  1038,   324,  1240,   861,   787,  1994,  1721,\n",
       "            832,   707,   435,   113,   138,   494,   920,  1707,  1134,  1003,\n",
       "            842,  1511,   193,  1936,  1478,  1261,   332,   756,   115,  1700,\n",
       "            324,  1074,  1631,  1575,   526,  1957,   756,   318,    19,   860,\n",
       "           1562,   164,  1477,  1450,     0],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   457,\n",
       "           2035,  1113,   504,  1301,     5,   739,   334,   178,  1832,  1803,\n",
       "            266,  1719,   516,   147,  1016,  1402,   709,  1046,  1620,   440,\n",
       "            996,   100,   551,  1799,  1930,  1811,  1551,  1026,  1440,   684,\n",
       "            313,    13,   629,  1930,   723,   457,   328,  1455,   796,   300,\n",
       "           1610,   435,   635,  1517,   958,  1607,  1013,   911,   958,   524,\n",
       "            457,  1019,  1019,   481,     0],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1547,\n",
       "            592,   601,  2022,  1795,    42,  1631,  1174,   496,  1640,   935,\n",
       "           1687,   654,  1105,   668,  1995,   918,  1002,  1668,   190,  1148,\n",
       "           1509,  1563,    30,  1669,   882,  1529,  1794,  1086,   900,   274,\n",
       "           1001,   482,    42,  1852,   780,   704,   275,  1073,  1174,  1618,\n",
       "           1540,  1344,  1371,   263,  1245,  1382,   253,   484,  2044,  1717,\n",
       "           1942,   165,  1832,   478,     0],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1433,\n",
       "           1154,  1672,   879,  1683,  1529,   561,   508,  1648,   358,   646,\n",
       "           1289,  1307,  1867,  1937,  1076,  1694,  1730,  1199,  1758,  1476,\n",
       "            369,   801,  1249,   260,  1759,   740,    53,   618,  2023,   119,\n",
       "            835,  2015,   835,    66,  1209,  1285,  1744,   804,  1863,  1240,\n",
       "            392,   741,  1834,  1193,  1440,  1696,  1470,  1810,  1464,   840,\n",
       "             43,  1978,   666,  1978,     0],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   948,\n",
       "            232,  1109,  1286,  1371,    94,  1516,   700,   714,   537,  1939,\n",
       "            334,    17,  1093,  1769,  1511,  1063,   444,  1399,  1594,    10,\n",
       "            532,   208,  1803,   945,  1193,  1082,  1667,   198,   382,   101,\n",
       "           1426,   458,  1587,  1450,  1722,  1173,  1286,   127,   225,  1482,\n",
       "           1368,   370,  1003,  1808,  1772,   952,   992,  1977,   820,   481,\n",
       "            945,   945,  1477,  1665,     0]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
