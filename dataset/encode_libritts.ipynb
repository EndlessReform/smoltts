{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/audio/dual-ar/.venv/lib/python3.9/site-packages/transformers/models/mimi/modeling_mimi.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, concatenate_datasets\n",
    "from transformers import MimiModel, AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"kyutai/mimi\")\n",
    "model = MimiModel.from_pretrained(\"kyutai/mimi\")\n",
    "model = model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"./encoded_libritts\")\n",
    "dataset = dataset.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1049, 1114, 1609,  784,  499,  260, 1011,    8, 1407,  540, 1615,  561,\n",
       "         1945,  201, 1324,  668,  376, 1849,    9, 1921, 1921, 1683,  228,  897,\n",
       "         1677,  518],\n",
       "        [ 811, 1149,  739,  410, 1367, 1305, 2046, 1287,  886, 1995, 1727,  678,\n",
       "         1455,  352, 1914, 1504, 1138, 1154,  669, 1217, 1450, 1003, 1711,  488,\n",
       "          342,  844],\n",
       "        [ 373, 1464, 2013, 1306,  102,  561,  852,  267,  442,  718, 1501, 1455,\n",
       "          233, 1015,  963,   29,  496, 1728,  783, 1870,  879, 1802, 1523,  231,\n",
       "          333,  199],\n",
       "        [ 131, 1957,   58,  500, 1489, 1451, 1946, 1800,   68,   46,  214, 2008,\n",
       "          539,  217,  403, 1270,  112, 1922,  104,  962, 1194, 1785,   36,  603,\n",
       "          212,  104],\n",
       "        [  68,  674, 1446, 1356,  457,   49,  541,  505,  122,  457, 1773,   44,\n",
       "          823, 1423, 1693,  644,  297,  272,  720,   91,  635, 1187,   64,  485,\n",
       "          844,  417],\n",
       "        [1739,  954,  935,  640, 1509,   63,  398, 1824,  707, 1948, 1273, 1832,\n",
       "          553, 1245,  110, 1521, 1865, 1554,  317, 1349,  853, 1955,  693,  648,\n",
       "         1760,   38],\n",
       "        [1238, 1560, 1151, 1486, 1575, 1451, 1491, 1389, 1967,  277, 1175, 1285,\n",
       "         1240,  467, 1202, 1507,  848,  358,  428, 1667, 1888, 1039,   75, 1364,\n",
       "         1412, 1242],\n",
       "        [ 754, 1956,   28, 1921, 1079,  729,  414, 1887, 1508,  585, 1804, 1803,\n",
       "          156,  927,  407,  406,  396, 1978, 1321, 1880,  298, 1300, 1513, 1213,\n",
       "          275, 1477]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "codes = dataset['dev.clean'][0]['codes']\n",
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_input = codes.to('cuda').to(torch.long).unsqueeze(0)\n",
    "out_pcm = model.decode(codes_input)\n",
    "torchaudio.save(\"out.wav\", out_pcm.audio_values[0].to(\"cpu\"), 24000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
